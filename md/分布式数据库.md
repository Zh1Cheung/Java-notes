## **什么是分布式数据库**

- **分布式数据库是服务于写多读少、低延时、海量并发 OLTP 场景的，具备海量数据存储能力和高可靠性的关系型数据库**。
- 外部视角
  - 定义1.0 OLTP关系型数据库
    - 写多读少、低延时、高并发
      - 之所以强调写多读少，因为写操作的负载只能是单体数据库的主节点上，是无法 转移的;而读操作，如果对一致性要求不高可以转移到备节点，甚至在某些条件下还能保证一致 性。就是说单体数据库可以通过一主多备解决读负载大的问题，而无需引入分布式数据库
  - 定义 2.0 + 海量并发
    - 传统关系型数据库往往是单机模式，也就是主要负载运行在一台机器上。这样，数据库的 并发处理能力与单机的资源配置是线性相关的，所以并发处理能力的上限也就受限于单机 配置的上限。这种依靠提升单机资源配置来扩展性能的方式，被称为**垂直扩展**(Scale Up)。
    - 分布式数据库就不同了，在维持关系型数据库特性不变的基础上，它可以通过**水平扩展**，也就是增加机器数量的方式，提供远高于单体数据库的并发量。这个并发量几乎不受 单机性能限制，我将这个级别的并发量称为“海量并发”。
  - 定义 3.0 + 高可靠
    - 我猜你会建议用 RAID(独立冗余磁盘阵列)来提高磁盘的可靠性。这确实是一个办法，但 也会带来性能上的损耗和存储空间上的损失。分布式数据库的副本机制可以比 RAID 更好地平衡可靠性、性能和空间利用率三者的关系。**副本机制就是将一份数据同时存储在多个 机器上，形成多个物理副本。**
    - 回到数据库的话题上，可靠性还要更复杂一点，包括两个度量指标，恢复时间目标 (Recovery Time Objective, RTO)和恢复点目标(Recovery Point Objective, RPO)。**RTO 是指故障恢复所花费的时间，可以等同于可靠性;RPO 则是指恢复服务后丢 失数据的数量。**
      - 数据库存储着重要数据，而金融行业的数据库更是关系到客户资产安全，不能容忍任何数 据丢失。所以，数据库高可靠意味着 RPO 等于 0，RTO 小于 5 分钟。
      - 分布式数据 库则是一个很好的备选方案，它**凭借节点之间的互为备份、自动切换的机制**，降低了 x86 服务器的单点故障对系统整体的影响，提供了高可靠性保障。
  - 定义 4.0 + 海量存储
    - 虽然单体数据库依靠外置存储设备可以扩展存储能力，但这种方式本质上不是数据库的能 力。现在，借助分布式的**横向扩展架构**，通过物理机的本地磁盘就可以获得强大的存储能 力，这让海量存储成为分布式数据库的标配。

- 内部构成
  - **客户端组件 + 单体数据库**
    - 通过独立的逻辑层建立数据分片和路由规则，实现单体数据库的初步管理，使应用能够对 接多个单体数据库，实现并发、存储能力的扩展。其作为应用系统的一部分，对业务侵入 较为深。
    - 这种客户端组件的典型产品是 Sharding-JDBC。
  - **代理中间件 + 单体数据库**
    - 以独立中间件的方式，管理数据规则和路由规则，以独立进程存在，与业务应用层和单体 数据库相隔离，减少了对应用的影响。随着代理中间件的发展，还会衍生出部分分布式事 务处理能力。
    - 这种中间件的典型产品是 MyCat。
  - **单元化架构 + 单体数据库**
    - 单元化架构是对业务应用系统的彻底重构，**应用系统被拆分成若干实例，配置独立的单体 数据库，让每个实例管理一定范围的数据。**例如对于银行贷款系统，可以为每个支行搭建 独立的应用实例，管理支行各自的用户，当出现跨支行业务时，由应用层代码通过分布式 事务组件保证事务的 ACID 特性。
  - 看过这三种方案，我相信你能够明白，它们共同的特点是单体数据库仍然能够被应用系统 感知到。相反，分布式数据库则是**将技术细节收敛到产品内部，以一个整体面对业务应用。**



## **强一致性**

- 强一致性意味着什么
  - 有人说，只要使用了 Paxos 或者 Raft算法，就可以实现强一致性;也有人说，根据 CAP 原理只能三选二，分区容忍性和高可用 性又是必不可少的，所以分布式数据库是做不到强一致性的。可是，**这些观点或多或少都 是有问题的**。
  - 对于分布式系统而言，一致性是在探讨当系统内的一份逻辑数据存在多个物理的数据副本 时，对其执行读写操作会产生什么样的结果，这也符合 CAP 理论对一致性的表述。
  - 而在数据库领域，“一致性”与事务密切相关，又进一步细化到 ACID 四个方面。其中，I 所代表的隔离性(Isolation)，是“一致性”的核心内容，研究的就是如何协调事务之间 的冲突。
  - 因此，当我们谈论分布式数据库的一致性时，实质上是在谈论**数据一致性**和**事务一致性**两个方面。
- **数据一致性**
  - 包括分布式数据库在内的分布式存储系统，为了避免设备与网络的不可靠带来的影响，通 常会存储多个数据副本。逻辑上的一份数据同时存储在多个物理副本上，自然带来了数据 一致性问题。
  - 强一致性:MySQL全同步复制
    - 显然，用户获得响应时，主库和备库的数据副本已经达成一致，所以后续的读操作肯定是 没有问题的，但这种模式的副作用非常大，体现在性能差、可用性问题。
    - 集群规模越大，这些问题就越严重，所以全同步复制模式在生产系统中也很少使用。更进 一步说，在工程实践中，实现状态视角的强一致性需要付出的代价太大，尤其是与可用性 有无法回避的冲突，所以很多产品选择了状态视角的弱一致性。
  - 弱一致性:NoSQL 最终一致性
    - NoSQL 产品是应用弱一致性的典型代表，但对弱一致性的接受仍然是有限度的，这就是 BASE 理论中的 E 所代表的最终一致性(Eventually Consistency)，弱于最终一致性的产 品就几乎没有了。
    - 对于最终一致性，你可以这样理解:在主副本执行写操作并反馈成功时，不要求其他副本 与主副本保持一致，但在经过一段时间后这些副本最终会追上主副本的进度，重新达到数 据状态的一致。
    - 你再仔细推敲一下，是不是觉得这个定义还有点含糊?“经过一段时间”到底是多久呢? 几秒还是几分钟?如果是一个不确定的数值，怎么在工程中使用呢?
- **操作视角**
  - **写后读一致性**
    - 它也称为“读写一致 性”，或“读自己写一致性”(Read My Writes Consistency)。你可能觉得最后一个名 字听上去有些奇怪，但它却最准确地描述了这种一致性模型的使用效果。
    - 自己写入成功的任何数据，下一刻一定能读取到，其内容保证与自己最后一次写入完全一 致，这就是“读自己写一致性”名字的由来。
  - **单调读一致性**
    - 关于单调读一致性的定义，常见的解释是这样的:一个用户一旦读到某个值，不会读到比这 个值更旧的值。
    - 实现单调读一致性的方式，可以是将用户与副本建立固定的映射关系，比如使用哈希算法 将用户 ID 映射到固定副本上，这样避免了在多个副本中切换。
  - **前缀一致性**
    - 小明和小红的评论分别写入了节点 N1 和 N2，但是它们与 N3 同步数据时，由于网络传输 的问题，N3 节点接收数据的顺序与数据写入的顺序并不一致，所以小刚是**先看到答案后看 到问题**。
    - 显然，问题与答案之间是有因果关系的，但这种关系在复制的过程中被忽略了，于是出现 了异常。
    - 保持这种因果关系的一致性，被称为**前缀读**或**前缀一致性**(Consistent Prefix)。要实现 这种一致性，可以考虑在原有的评论数据上增加一种显式的因果关系，这样系统可以据此 控制在其他进程的读取顺序。
  - **线性一致性**
    - 在“前缀一致性”的案例中，问题与答案之间存在一种显式声明，但在现实中，多数场景 的因果关系更加复杂，也不可能要求全部做显式声明。
    - 线性一致性(Linearizability)就是建立在事件的先后顺序之上的。在线性一致性下，整个 系统表现得好像只有一个副本，所有操作被记录在一条时间线上，并且被原子化，这样任 意两个事件都可以比较先后顺序。
    - 但是，集群中的各个节点不能做到真正的时钟同步，这样节点有各自的时间线。那么，如 何将操作记录在一条时间线上呢?这就需要一个绝对时间，也就是**全局时钟**。
  - **因果一致性**
    - 既然线性一致性不够完美，那么有没有不依赖绝对时间的方法呢?
    - 因果一致性的基础是**偏序关系**，也就是说，部分事件顺序是可以比较的。至少一个节点内 部的事件是可以排序的，依靠节点的本地时钟就行了;节点间如果发生通讯，则参与通讯 的两个事件也是可以排序的，接收方的事件一定晚于调用方的事件。
    - 借助**逻辑时钟**仍然可以建立全序关系，当然这个全序关系是不够精确的。因为如果两个事 件并不相关，那么逻辑时钟给出的大小关系是没有意义的。
    - 多数观点认为，**因果一致性弱于线性一致性，但在并发性能上具有优势**，也足以处理多数 的异常现象，所以因果一致性也在工业界得到了应用。
    - 因果一致性是靠逻辑时钟确定偏序关系，**不需要应用介入**;而前缀一 致性靠事件之间显式声明的依赖关系，**可以在应用层处理**
- 有些时候 大家又会将 Paxos 称为一致性协议。你觉得这个“一致性协议”和数据一致性又是什么关 系呢?
  - 数据一致性是从数据的用户视角出发对数据属性的描述，而paxos协议是达成共识 的过程的一种实现方式，是从数据的生产者或者维护者角度出发的
    - 从状态视角看，是不是只有全同步这种方式实现了强一致性，即使像paxos、raft这些实现了操作上线性一致性的算法，从状态视角看也不是强一致的。
    - 然而全同步降低了系统的可用性，paxos、raft不保证所有节点状态的一致，而是通过额外 的算法来保证操作视角的一致性，同时提高了系统的可用性。
  - **一致性模型里有两个要点，读写策略和多副本状态**
    - Raft是多数派协议，从写入成功那一刻的数据状态来说，肯定不是一致的。不过，通过操作方面 的封装，约定由主副本对外提供服务，所以不会体现出副本间的差异。一致性模型，除了副本的 状态，还要看读写操作。**最终一致性的定义，其实只是描述了副本的状态而已。**我认为，一致性 模型，主要还是从读写操作的效果来分析，也数据副本的一致性有关但不是强依赖。比如，如果 不使用Raft，用半同步，也可以做到线性一致性。
  - CAP的C也是Consistency，是多副本、单操作的数据一致性;而ACID里的 C是指单副本、多操作的事务一致性。
    - Paxos这类共识算法，可以看作是复制协议的一种，虽然有 时也叫做一致性协议，但这个一致性是指Consensus。**Consensus是实现数据一致性目标下的具 体技术，但并不是唯一的选择。**采用主从复制也可以达到同样效果，比如PGXC风格的分布式数据库就是采用主从复制的方式。
    - CAP中的C就是Consistency，是数据一致性，也是我们所说的操作视角的一致 性，这里包含的多副本和读写策略两层含义。共识算法是复制协议层面的内容，并不一定对操作 做严格定义。比如，就算我们使用Raft算法，但是如果开放了Follower读，也有可能达不到线性 一致性或因果一致性的。事实上，CockroachDB的Follower读就是这样的。
- **事务一致性**
  - 虽然 ACID 名义上并列为事务的四大特性，但它们对于数据库的重要程度并不相同。
    - 第一个是**一致性，它无疑是其中存在感最低的特性，可以看作是对 “事务”整体目标的阐 述。**它并没有提出任何具体的功能需求，所以在数据库中也很难找到针对性的设计。
    - 第二个是持久性，它不仅是对数据库的基本要求。如果你仔细琢磨下持久性的定义，就会 发现**它的核心思想就是要应对系统故障**。怎么理解系统故障呢?我们可以把故障分为两 种。
      - **存储硬件无损、可恢复的故障**。这种情况下，主要依托于预写日志(Write Ahead Log, WAL)保证第一时间存储数据。WAL 采用顺序写入的方式，可以保证数据库的低延时 响应。WAL 是单体数据库的成熟技术，NoSQL 和分布式数据库都借鉴了过去。
      - **存储硬件损坏、不可恢复的故障**。这种情况下，需要用到日志复制技术，将本地日志及 时同步到其他节点。实现方式大体有三种:第一种是单体数据库自带的同步或半同步的 方式，其中半同步方式具有一定的容错能力，实践中被更多采用;第二种是将日志存储 到共享存储系统上，后者会通过冗余存储保证日志的安全性，亚马逊的 Aurora 采用了 这种方式，也被称为 Share Storage;第三种是基于 Paxos/Raft 的共识算法同步日志 数据，在分布式数据库中被广泛使用。无论采用哪种方式，目的都是保证在本地节点之 外，至少有一份完整的日志可用于数据恢复。
    - 第三个是原子性，是数据库区别于其他存储系统的重要标志。在单体数据库时代，原子性 问题已经得到妥善解决，但**随着向分布式架构的转型，在引入不可靠的网络因素后，原子 性又成为一个新的挑战。**
      - **分布式数据库是在分布式架构上实现的关系型数 据库，那么就必须支持事务，首先就要支持原子性。**原子性，在实现机制上较为复杂，目标却很简单，和分成多个级别的隔离性不同，原子性就只有支持和不支持的区别。
    - 最后一个是隔离性，它是事务中最复杂的特性。隔离性分为多个隔离级别，较低的隔离级 别就是在正确性上做妥协，将一些异常现象交给应用系统的开发人员去解决，从而获得更 好的性能。
  - 1995 年，Jim Gray 等人 发表了论文“A Critique of ANSI SQL Isolation Levels”(以下简称 **Critique**)，对于 事务隔离性进行了更加深入的分析
    - **幻读和写倾斜**无疑则是通往最高隔离级别的两座大山
      - Critique 对幻读的描述大致是这样的，事务 T1 使用特定的查询条件获得一个结果集，事 务 T2 插入新的数据，并且这些数据符合 T1 刚刚执行的查询条件。T2 提交成功后，T1 再 次执行同样的查询，此时得到的结果集会增大。这种异常现象就是幻读。
      - 不少人会将幻读与不可重复读混淆，这是因为它们在自然语义上非常接近，都是在一个事 务内用相同的条件查询两次，但两次的结果不一样。差异在于，**对不可重复读来说，第二 次的结果集相对第一次，有些记录被修改(Update)或删除(Delete)了;而幻读是第二 次结果集里出现了第一次结果集没有的记录 (Insert)。一个更加形象的说法，幻读是在第一 次结果集的记录“间隙”中增加了新的记录**。所以，MySQL 将防止出现幻读的锁命名为间 隙锁(Gap Lock)。
    - 写倾斜要稍微复杂一点，我用一个黑白球的例子来说明
      - 首先，箱子里有三个白球和三个黑球，两个事务(T1,T2)并发修改，不知道对方的存在。 T1 要让 6 个球都变成白色;T2 则希望 6 个球都变成黑色。
      - 根据可串行化的定义，“多事务并行执行所得到的结果，与串行执行(一个接一个)完全 相同”。比照两张图，很容易发现事务并行执行没有达到串行的同等效果，所以这是一种 异常现象。也可以说，写倾斜是一种更不易察觉的更新丢失。
  - 隔离性的产品实现
    - 第一个方向是，用真正的串行化实现“可串行化”隔离。我们往往认为多线程并发在性能 上更优，但 **Redis 和 VoltDB** 确实通过串行化执行事务的方式获得了不错的性能。考虑到 VoltDB 作为一款分布式数据库的复杂度，其成功就更为难得了。我想，其中部分原因可能 在于内存的大量使用，加速了数据计算的过程。另外，VoltDB 以存储过程为逻辑载体的方 式，也使得事务有了更多的优化机会。
    - 如果说第一个方向有点剑走偏锋，那第二个方向就是硬桥硬马了。没错，还是在并发技术 上继续做文章。PostgreSQL 在 2008 年提出了 **Serializable Snapshot Isolation (SSI)， 这实际就是可串行化**。而后，兼容 PostgreSQL 生态的 CockroachDB，也同样选择支持 SSI，而且是唯一支持的隔离级别。
- **分布式数据库的强一致性**
  
  - | 隔离级别         | 线性一致性     | 因果一致性  |
    | ---------------- | -------------- | ----------- |
    | 可串行化（SSL）  | Spanner        | CockroachDB |
    | 快照隔离（SL）   | TiDb           | YugabyteDB  |
    | 可重复度读（RR） | GolenDB        |             |
    | 已提交读（RC）   | OceanBase 2.0+ |             |





## NewSQL和PGXC

- **总的来说，分布式数据库大多可以分为两种架构风格**
  - 一种是 NewSQL，它的代表系统是 Google Spanner;
  - 另一种是从单体数据库中间件基础上演进出来的，被称为 Prxoy 风 格，没有公认的代表系统，便于理解，所以选了一个出现较早的产品来指代这种风 格，这就是 PostgreSQL-XC(下文简称 PGXC)。
- 数据库的基本架构
  - 数据库从逻辑上拆分为 5 个部分，分别是客户端 通讯管理器 (Client Communications Manager)、查询处理器(Relational Query Processor)、事务存储管理器(Transactional Storage Manager)、进程管理器 (Process Manager)和共享组件与工具 (Shared Components and Utilities)，每个部 分下面又可以拆分成一些组件。
  - **客户端通讯管理器。**这是应用开发者能够直观感受到的模块，通常我们使用 JDBC 或者 ODBC 协议访问数据库时，连接的就是这个部分。
  - **进程管理器。**连接建好了，数据库会为客户端分配一个进程，客户端后续发送的所有操 作都会通过对应的进程来执行。
  - **查询处理器。**它包括四个部分，功能上是顺序执行的。首先是**解析器**，它将接收到的 SQL 解析为内部的语法树。然后是**查询重写(Query Rewrite)**，它也被称为逻辑优 化，主要是依据关系代数的等价变换，达到简化和标准化的目的，比如会消除重复条件 或去掉一些无意义谓词 ，还有将视图替换为表等操作。再往后就是**查询算法优化 (Query Optimizer)**，它也被称为物理优化，主要是根据表连接方式、连接顺序和排 序等技术进行优化，我们常说的基于规则优化(RBO)和基于代价优化(CBO)就在这 部分。最后就是**计划执行器(Plan Executor)**，最终执行查询计划，访问存储系统。
  - **事务存储管理器。**它包括四个部分，其中访问方式(Access Methods)是指数据在磁 盘的具体存储形式。锁管理(Lock Manager)是指并发控制。日志管理(Log Manager)是确保数据的持久性。缓存管理(Buffer Manager)则是指 I/O 操作相关 的缓存控制。
  - **共享组件和工具。**在整个过程中还会涉及到的一些辅助操作，当然它们对于数据库的运 行也是非常重要的。例如编目数据管理器(Catalog Manager)会记录数据库的表、字 段、视图等元数据信息，并根据这些信息来操作具体数据内容。**复制机制 (Replication)也很重要，它是实现系统高可靠性的基础**，在单体数据库中，通过主备 节点复制的方式来实现数据的复制。
- **PGXC**:单体数据库的自然演进
  - 单体数据库的功能看似已经很完善了，但在面临高并发场景的时候，还是会碰到写入性能 不足的问题，很难解决。因此，也就有了向分布式数据库演进的动力。要解决**写入性能不足的问题**，大家首先想到的，最简单直接的办法就是**分库分表**。
    - 分库分表方案就是在多个单体数据库之前增加代理节点，**本质上是增加了 SQL 路由功能**。 这样，**代理节点首先解析客户端请求，再根据数据的分布情况，将请求转发到对应的单体 数据库。**
    - **代理节点需要实现三个主要功能，它们分别是客户端接入、简单的查询处理器和进程管理 中的访问控制。**
    - 另外，分库分表方案还有一个重要的功能，那就是**分片信息管理**，分片信息就是数据分布 情况，是区别于编目数据的一种元数据。不过考虑到分片信息也存在多副本的一致性的问 题，大多数情况下它会独立出来
    - 显然，如果把每一次的事务写入都限制在一个单体数据库内，业务场景就会很受局限。因 此，跨库事务成为必不可少的功能，但是单体数据库是不感知这个事情的，所以我们就要**在代理节点增加分布式事务组件**。
    - 同时，简单的分库分表不能满足全局性的查询需求，因为每个数据节点只能看到一部分数 据，有些查询运算是无法处理的，比如排序、多表关联等。所以，**代理节点要增强查询计算能力，支持跨多个单体数据库的查询**。
    - 随着分布式事务和跨节点查询等功能的加入，**代理节点已经不再只是简单的路由功能，更 多时候会被称为协调节点。**
    - 



































