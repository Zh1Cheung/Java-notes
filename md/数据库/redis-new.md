# 前言

- 相关的性能问题

  - **为了保证数据的可靠性**，Redis 需要在磁盘上读写 AOF 和 RDB，但在高并发场景里，这就会直接带来两个新问题:一个是写 AOF 和 RDB 会造成 Redis 性能抖动，另一个是 Redis 集群数据同步和实例恢复时，读 RDB 比较 慢，限制了同步和恢复速度。
  - 一个可行的解决方 案就是使用非易失内存 NVM，因为它既能保证高速的读写，又能快速持久化数据。

- 遇见的“坑”，总体来说集中在四个方面:

  - CPU 使用上的“坑”，例如数据结构的复杂度、跨 CPU 核的访问; 
  - 内存使用上的“坑”，例如主从同步和 AOF 的内存竞争; 
  - 存储持久化上的“坑”，例如在 SSD 上做快照的性能抖动;
  -  网络通信上的“坑”，例如多实例时的异常网络丢包。

- Redis 知识全景图

  - 应用维度：缓存、集群、数据结构
  - 系统维度：高性能主线、高可靠主线、高可扩展主线
    - 处理层：线程模型、主从复制、数据分片
    - 内存层：数据结构、哨兵机制、——
    - 存储层：持久化、——、负载均衡
    - 网络层：epoll网络框架、——、——

- 知识体系

  - 在应用维度上，我建议你按照两种方式学习: “**应用场景驱动**”和“**典型案例驱 动**”，一个是“面”的梳理，一个是“点”的掌握。
    - 我们知道，缓存和集群是 Redis 的两大广泛的应用场景。在这些场景中，本身就具有一条 显式的技术链。比如说，提到缓存场景，你肯定会想到缓存机制、缓存替换、缓存异常等 一连串的问题。
    - 可以用“典型案例驱动”的方式学习。我们可以重点解读一些对 Redis 的“三高”特性影响较大的使用案例，例如，多家大厂在万亿级访问量和万亿级数据量的 情况下对 Redis 的深度优化，解读这些优化实践，非常有助于你透彻地理解 Redis。而 且，你还可以梳理一些方法论，做成 Checklist，就像是一个个锦囊，之后当你遇到问题的 时候，就可以随时拿出自己的“锦囊妙计”解决问题了。
  - Redis 的问题画像
    - ![img](https://static001.geekbang.org/resource/image/70/b4/70a5bc1ddc9e3579a2fcb8a5d44118b4.jpeg)

  

  

  

# **基本架构**

- **Redis 能够在实际业务场景中得到广泛的应用，就是得益于支持多样化类型的 value**。
- 大体来说，一个键值数据库包括了**访问框架、索引模块、操作模块和存储模块**四部分
  - PUT hello world：键值数据库网络框架接收到网络包，并按照相应的协议进行解析之后，就可以知道，客户端想写入一个键值对，并开始实际的写入流程。此时，我们会遇到一个系统设计上的问 题，简单来说，就是网络连接的处理、网络请求的解析，以及数据存取的处理，是用一个线程、多个线程，还是多个进程来交互处理呢?该如何进行设计和取舍呢?我们一般把这 个问题称为 **I/O 模型设计**。不同的 I/O 模型对键值数据库的性能和可扩展性会有不同的影 响。
  - **索引的作用是让 键值数据库根据 key 找到相应 value 的存储位置，进而执行操作**。
    - 索引的类型有很多，常见的有哈希表、B+ 树、字典树等。不同的索引结构在性能、空间消 耗、并发控制等方面具有不同的特征。
    - 一般而言，内存键值数据库(例如 Redis)采用**哈希表**作为索引，很大一部分原因在于， 其键值数据基本都是保存在内存中的，而内存的高性能随机访问特性可以很好地与哈希表 O(1) 的操作复杂度相匹配。
    - 对于 Redis 而言，很有意思的一点是，它的 value 支持多种类型，当我们通过索引找到一个 key 所对应的 value 后，仍然需要从 value 的复杂结构(例如集合和列表)中进一步找到 我们实际需要的数据，这个操作的效率本身就依赖于它们的实现结构。
    - **Redis 采用一些常见的高效索引结构作为某些 value 类型的底层数据结构，这一技术路线 为 Redis 实现高性能访问提供了良好的支撑。**
  - 对于 PUT 和 DELETE 两种操作来说，除了新写入和删除键值对，还 需要分配和释放内存。
  - Redis 也提供了持久化功能。不过，为了适应不同的业务场景，Redis 为持久化提供了诸多的执行机制和优化改进





# **数据结构**

- 重要的表现:它接收到一个键值对操作后， 能以**微秒级别**的速度找到数据，并快速完成操作。

  - 为啥 Redis 能有这么突出的表现呢?一方面，这是因为它是内存数据库， 所有操作都在**内存**上完成，内存的访问速度本身就很快。另一方面，这要归功于它的**数据结构**。

- String 类型的底层实现只有一种数据结构，也就是简单动态字符串。而 List、 Hash、Set 和 Sorted Set 这四种数据类型，都有两种底层实现结构。通常情况下，我们会 把这四种类型称为集合类型，它们的特点是**一个键对应了一个集合的数据**。

- **键和值用什么结构组织?**

  - **为了实现从键到值的快速访问，Redis 使用了一个哈希表来保存所有键值对。**
    - 因为这个哈希表保存了所有的键值对，所以，我也把它称为**全局哈希表**。哈希表的最大好 处很明显，就是让我们可以用 **O(1)** 的时间复杂度来快速查找到键值对——我们只需要计算 键的哈希值，就可以知道它所对应的哈希桶位置，然后就可以访问相应的 entry 元素
    - 一个哈希表，其实就是一个数组，数组的每个元素称为一个哈希桶。所以，我们常说，**一个哈希表是由多个哈希桶组成的，每个哈希桶中保存了键值对数据。**
    - **哈希桶中的元素保存的并不是值本身，而是指向具体值的指针。**
  - 但是，如果你只是了解了哈希表的 O(1) 复杂度和快速查找特性，那么，当你往 Redis 中 写入大量数据后，就可能发现操作有时候会突然变慢了。这其实是因为你忽略了一个潜在 的风险点，那就是**哈希表的冲突问题和 rehash 可能带来的操作阻塞。**

- **为什么哈希表操作变慢了**?

  - Redis 解决哈希冲突的方式，就是链式哈希。链式哈希也很容易理解，就是指**同一个哈希 桶中的多个元素用一个链表来保存，它们之间依次用指针连接**。

  - **哈希冲突**可能也会越来越多，这就会导致某些哈希冲突链 过长，进而导致这个链上的元素查找耗时长，效率降低。对于追求“快”的 Redis 来说， 这是不太能接受的。

  - 所以，Redis 会对哈希表做 **rehash 操作**。rehash 也就是增加现有的哈希桶数量，让逐渐 增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个 桶中的冲突。

    - **为了使 rehash 操作更高效，Redis 默认使用了两个全局哈希表**

      - ```
        1. 给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍; 2. 把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中;
        3. 释放哈希表 1 的空间。
        ```

      - 这个过程看似简单，但是第二步涉及大量的数据拷贝，如果一次性把哈希表 1 中的数据都 迁移完，会造成 Redis 线程阻塞，无法服务其他请求。此时，Redis 就无法快速访问数据 了。

    - 为了避免这个问题，Redis 采用了**渐进式 rehash**。

      - 简单来说就是在第二步拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求 时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝 到哈希表 2 中;等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries。
      - 这样就巧妙地把一次性大量拷贝的开销，分摊到了多次处理请求的过程中，避免了耗时操作，保证了数据的快速访问。

- **有哪些底层数据结构?**

  -       a，string：简单动态字符串
          b，list：双向链表，压缩列表
          c，hash：压缩列表，哈希表
          d，Sorted Set：压缩列表，跳表
          e，set：哈希表，整数数组

  - 集合类型的底层数据结构主要有 5 种:整数数组、双向链表、哈 希表、压缩列表和跳表。

    - **压缩列表实际上类似于一个数组**，数组中的每一个元素都对应保存一个数据。和数组不同 的是，压缩列表在表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的 偏移量和列表中的 entry 个数;
    - 压缩列表在表尾还有一个 zlend，表示列表结束。
    - 在压缩列表中，如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段 的长度直接定位，复杂度是 O(1)。而查找其他元素时，就没有这么高效了，只能逐个查 找，此时的复杂度就是 O(N) 了。

  - 有序链表只能逐一查找元素，导致操作起来非常缓慢，于是就出现了跳表。具体来说，跳 表在链表的基础上，**增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位。O(logn)**

- **不同操作的复杂度**

  - 单元素操作是基础;
  - 范围操作非常耗时;
  - 统计操作（是指**集合类型对集合中所有元素个数的记录**）通常高效;
    - 例如 LLEN 和 SCARD。这 类操作复杂度只有 O(1)，这是因为当集合类型采用压缩列表、双向链表、整数数组这些数 据结构时，这些结构中专门记录了元素的个数统计，因此可以高效地完成相关操作。
  - 例外情况只有几个。
    - 是指某些数据结构的特殊记录，例如**压缩列表和双向链表都会记录表头 和表尾的偏移量**。这样一来，对于 List 类型的 LPOP、RPOP、LPUSH、RPUSH 这四个操 作来说，它们是在列表的头尾增删元素，这就可以通过偏移量直接定位，所以它们的复杂 度也只有 O(1)，可以实现快速操作。

- 整数数组和压缩列表在查找时间复杂度方面并没有很大的优势，那为什么 Redis 还会把它 们作为底层数据结构呢?

  - **内存利用率**，数组和压缩列表都是非常紧凑的数据结构，它比链表占用的内存要更少。Redis是内存数据库，大量数据存到内存中，此时需要做尽可能的优化，提高内存的利用率。
  - **数组对CPU高速缓存支持更友好**，所以Redis在设计时，集合数据元素较少情况下，默认采用内存紧凑排列的方式存储，同时利用CPU高速缓存不会降低访问速度。当数据元素超过设定阈值后，避免查询时间复杂度太高，转为哈希和跳表数据结构存储，保证查询效率。





# 高性能IO模型

- 我们通常说，Redis 是单线程，主要是指 **Redis 的网络 IO 和键值对读写是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程**。 但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执 行的。

- **Redis为什么用单线程?**

  - **多线程的开销**
    - **我们刚开始增加线程数时，系统吞吐率会增加，但是，再进一步增加线程时，系统吞吐率就增长迟缓了，有时甚至还会出现下降的情况。**一个关键的瓶颈在于，系统中通常会存在被多线程同时访问的共享资源，比如一个共享的数据结构。当有多个线程要修改这个共享资源时，为了保证共享资源的正确性，就需要有额外的机制进行保证，而这个额外的机制，就会带来额外的开销。
    - **多线程编程模式面临的共享资源的 并发访问控制问题**。
    - 采用多线程开发一般会引入同步原语来保护共享资源的并发访问，这也会降低系统 代码的易调试性和可维护性。为了避免这些问题，Redis 直接采用了单线程模式。
  - **单线程** **Redis** **为什么那么快?**
    - Redis 却能使用单线程模型达到每 秒数十万级别的处理能力
    - 一方面，Redis 的大部分操作在**内存**上完成，再加上它采用了高效的数据结构，例如哈希 表和跳表，这是它实现高性能的一个重要原因。另一方面，就是 Redis 采用了**多路复用机制**，使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率。

- **基本** **IO** **模型与阻塞点**

  - 以 Get 请求为例，SimpleKV 为了处理一个 Get 请求，需要监听客户端请求 (bind/listen)，和客户端建立连接(accept)，从 socket 中读取请求(recv)，解析 客户端发送请求(parse)，根据请求类型读取键值数据(get)，最后给客户端返回结 果，即向 socket 中写回数据(send)。
    - **但是，在这里的网络 IO 操作中，有潜在的阻塞点，分别是 accept() 和 recv()。**当 Redis 监听到一个客户端有连接请求，但一直未能成功建立起连接时，会阻塞在 accept() 函数这 里，导致其他客户端无法和 Redis 建立连接。类似的，当 Redis 通过 recv() 从一个客户端 读取数据时，如果数据一直没有到达，Redis 也会一直阻塞在 recv()。
  - **非阻塞模式**
    - Socket 网络模型的非阻塞模式设置，主要体现在三个关键的函数调用上
    - 在 socket 模型中，不同操作调用后会返回不同的套接字类型。
      - socket() 方法会返回**主动套接字**
      - 然后调用 listen() 方法，将主动套接字转化为监听套接字，此时，可以监听来自客户 端的连接请求。
      - 最后，调用 accept() 方法接收到达的客户端连接，并返回**已连接套接字。**
    - 针对监听套接字，我们可以设置非阻塞模式:当 Redis 调用 accept() 但一直未有连接请求 到达时，Redis 线程可以返回处理其他操作，而不用一直等待。但是，你要注意的是，调用 accept() 时，已经存在监听套接字了。
    - 虽然 Redis 线程可以不用继续等待，但是总得有机制继续在监听套接字上等待后续连接请 求，并在有请求时通知 Redis。
      - 类似的，我们也可以针对已连接套接字设置非阻塞模式:Redis 调用 recv() 后，如果已连 接套接字上一直没有数据到达，Redis 线程同样可以返回处理其他操作。我们也需要有机 制继续监听该已连接套接字，并在有数据达到时通知 Redis。

- **基于多路复用的高性能** **I/O** **模型**

  - Linux 中的 IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，**该机制允许内核中，同时存在多个监听套接字和已连接套接字**。
    - 内核会一直监听这些套接字上的连接请求或数据 请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。
    - Redis 网络框架调用 epoll 机制，让内核监听这些套接字FD。
    - 为了在请求到达时能通知到 Redis 线程，select/epoll 提供了**基于事件的回调机制**，即**针 对不同事件的发生，调用相应的处理函数**。
  - select/epoll 一旦监测到 FD 上有请求到达时，就会**触发相应的事件**。
    - 这些事件会被放进一个**事件队列**，Redis 单线程对该事件队列不断进行处理。这样一来， Redis 无需一直轮询是否有请求实际发生，这就可以避免造成 CPU 资源浪费。同时， Redis 在对事件队列中的事件进行处理时，会调用相应的处理函数，这就实现了**基于事件的回调**。因为 Redis 一直在对事件队列进行处理，所以能及时响应客户端请求，提升 Redis 的响应性能。
    - 以连接请求和读数据请求为例
      - 这两个请求分别对应 Accept 事件和 Read 事件，Redis 分别对这两个事件注册 accept 和 get 回调函数。当 Linux 内核监听到有连接请求或读数据请求时，就会触发 Accept 事件 和 Read 事件，此时，内核就会回调 Redis 相应的 accept 和 get 函数进行处理。
      - **这就像病人去医院瞧病**。在医生实际诊断前，每个病人(等同于请求)都需要先分诊、测 体温、登记等。如果这些工作都由医生来完成，医生的工作效率就会很低。所以，医院都 设置了分诊台，分诊台会一直处理这些诊断前的工作(类似于 Linux 内核监听请求)，然 后再转交给医生做实际诊断。这样即使一个医生(相当于 Redis 单线程)，效率也能提 升。

- Redis单线程处理IO请求性能瓶颈主要包括2个方面：

  1、任意一个请求在server中一旦发生耗时，都会影响整个server的性能，也就是说后面的请求都要等前面这个耗时请求处理完成，自己才能被处理到。耗时的操作包括以下几种：
  a、操作bigkey：写入一个bigkey在分配内存时需要消耗更多的时间，同样，删除bigkey释放内存同样会产生耗时；
  b、使用复杂度过高的命令：例如SORT/SUNION/ZUNIONSTORE，或者O(N)命令，但是N很大，例如lrange key 0 -1一次查询全量数据；
  c、大量key集中过期：Redis的过期机制也是在主线程中执行的，大量key集中过期会导致处理一个请求时，耗时都在删除过期key，耗时变长；
  d、淘汰策略：淘汰策略也是在主线程执行的，当内存超过Redis内存上限后，每次写入都需要淘汰一些key，也会造成耗时变长；
  e、AOF刷盘开启always机制：每次写入都需要把这个操作刷到磁盘，写磁盘的速度远比写内存慢，会拖慢Redis的性能；
  f、主从全量同步生成RDB：虽然采用fork子进程生成数据快照，但fork这一瞬间也是会阻塞整个线程的，实例越大，阻塞时间越久；
  2、并发量非常大时，单线程读写客户端IO数据存在性能瓶颈，虽然采用IO多路复用机制，但是读写客户端数据依旧是同步IO，只能单线程依次读取客户端的数据，无法利用到CPU多核。

  针对问题1，一方面需要业务人员去规避，一方面Redis在4.0推出了lazy-free机制，把bigkey释放内存的耗时操作放在了异步线程中执行，降低对主线程的影响。

  针对问题2，Redis在6.0推出了多线程，可以在高并发场景下利用CPU多核多线程读写客户端数据，进一步提升server性能，当然，只是针对客户端的读写是并行的，每个命令的真正操作依旧是单线程的。







# AOF日志

- **一旦服务器宕机，内存中的数据将全部丢失**
- 目前，Redis 的持久化主要有两大机制，即 AOF 日志和 RDB 快照。
  - 说到日志，我们比较熟悉的是数据库的写前日志(Write Ahead Log, WAL)，也就是 说，在实际写数据前，先把修改的数据记到日志文件中，以便故障时进行恢复。不过， **AOF 日志正好相反，它是写后日志**，“写后”的意思是 Redis 是先执行命令，把数据写入 内存，然后才记录日志
  - 传统数据库的日志，例如 redo log(重做日志)，记录的是修改后的数据，而 **AOF 里记录的是 Redis 收到的每一条命令，这些命令是以文本形式保存的。**
  - AOF 还有一个好处:它是在命令执行后才记录日志，所以**不会阻塞当前的写操 作**。
- 不过，AOF 也有两个潜在的风险。
  - 首先，如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数 据就有丢失的风险。如果此时 Redis 是用作缓存，还可以从后端数据库重新读入数据进行恢复，但是，如果 Redis 是直接用作数据库的话，此时，因为命令没有记入日志，所以就 无法用日志进行恢复了。
  - 其次，AOF 虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险。这是因 为，AOF 日志也是在主线程中执行的，如果在把日志文件写入磁盘时，磁盘写压力大，就 会导致写盘很慢，进而导致后续的操作也无法执行了。
  - **这两个风险都是和 AOF 写回磁盘的时机相关的**。这也就意味 着，如果我们能够控制一个写命令执行完后 AOF 日志写回磁盘的时机，这两个风险就解除 了。
- **三种写回策略**
  - AOF 配置项 appendfsync 的三个可选值
    - **Always**，同步写回:每个写命令执行完，立马同步地将日志写回磁盘;
    - **Everysec**，每秒写回:每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘;
    - **No**，操作系统控制的写回:每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。
  - 想要获得高性能，就选择 No 策略;如果想要得到高可靠性保证，就选择 Always 策略;如果允许数据有一点丢失，又希望性能别受太大影响的话，那么就选择 Everysec 策略。
- AOF 是以文 件的形式在记录接收到的所有写命令。随着接收的写命令越来越多，AOF 文件会越来越 大。这也就意味着，我们一定要小心 AOF 文件过大带来的性能问题。
  - 这里的“性能问题”，主要在于以下三个方面:
    - 一是，文件系统本身对文件大小有限制， 无法保存过大的文件;
    - 二是，如果文件太大，之后再往里面追加命令记录的话，效率也会 变低;
    - 三是，如果发生宕机，AOF 中记录的命令要一个个被重新执行，用于故障恢复，如 果日志文件太大，整个恢复过程就会非常缓慢，这就会影响到 Redis 的正常使用。
- **日志文件太大了怎么办?**
  - 重写机制具有“多变一”功能。所谓 的“多变一”，也就是说，旧日志文件中的多条命令，在重写后的新日志中变成了一条命 令。
- **AOF重写会阻塞吗**
  - 和 AOF 日志由主线程写回不同，重写过程是由后台线程 bgrewriteaof 来完成的，这也是为了避免阻塞主线程，导致数据库性能下降。
  - 把重写的过程总结为“**一个拷贝，两处日志**”。
    - “一个拷贝”就是指，**每次执行重写时，主线程 fork 出后台的 bgrewriteaof 子进程**。fork子进程时，子进程是会拷贝父进程的页表，即虚实映射关系，而不会拷贝物理内存。子进程复制了父进程页表，也能共享访问父进程的内存数据 了，此时，类似于有了父进程的所有内存数据。然后，bgrewriteaof 子进程就可以在不影响主线程的情况下，逐一把拷贝的数 据写成操作，记入重写日志。
    - 因为主线程未阻塞，仍然可以处理新来的操作。此时，如果有写操作，第一处日志就是指 **正在使用的 AOF 日志**，**Redis 会把这个操作写到它的缓冲区。**这样一来，即使宕机了，这 个 AOF 日志的操作仍然是齐全的，可以用于恢复。
    - 而第二处日志，就是指**新的 AOF 重写日志**。**这个操作也会被写到重写日志的缓冲区**。这样，重写日志也不会丢失最新的操作。等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件，以保证数据库最新状态的记录。此时，我 们就可以用新的 AOF 文件替代旧文件了。
  - 总结来说，每次 AOF 重写时，Redis 会先执行一个内存拷贝，用于重写;然后，使用两个 日志保证在重写过程中，新写入的数据不会丢失。而且，因为 Redis 采用额外的线程进行 数据重写，所以，这个过程并不会阻塞主线程。
- Huge page在实际使用Redis时是建议关掉的
  - 这个特性在使用Redis也要注意。Huge page对提升TLB命中率比较友好，因为在相同的内存容量下，使用huge page可以减少页表项，TLB就可以缓存更 多的页表项，能减少TLB miss的开销。
  - 但是，这个机制对于Redis这种喜欢用fork的系统来说，的确不太友好，**尤其是在Redis的写入请求比较多的情况下**。**因为fork后，父进程修改数据采用写时复制**，复制的粒度为一个内存页。如果只是修改一个256B的数据，父进程需要读原来的内存页，然后再映射到新的物理地址写入。**一读一写会造成读写放大。**如果内存页越大(例如2MB的大页)，那么**读写放大也就越严重，对Redis性能造成影响。**





# **内存快照**

- 但是，也正因为记录的是操作命令，而不是实际的数据，所以，用 AOF 方法进行故障恢复 的时候，需要逐一把操作日志都执行一遍。如果操作日志非常多，Redis 就会恢复得很缓慢，影响到正常使用。这当然不是理想的结果。那么，还有没有既可以保证可靠性，还能在宕机时实现快速恢复的其他方法呢?
  - 和 AOF 相比，RDB 记录的是某一时刻的数据，并不是操作，所以，在做数据恢复时，我 们可以直接把 RDB 文件读入内存，很快地完成恢复。
- 考虑两个关键问题
  - 对哪些数据做快照?这关系到快照的执行效率问题;
  - 做快照时，数据还能被增删改吗?这关系到 Redis 是否被阻塞，能否同时正常处理请 求。
- **给哪些内存数据做快照?**
  - Redis 的数据都在内存中，为了提供所有数据的可靠性保证，它执行的是**全量快照**，也就 是说，把内存中的所有数据都记录到磁盘中
- 对于 Redis 而言，它的单线程模型就决定了，我们要尽量避免所有会阻塞主线程的操作
  - Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave。
  - **save**:在主线程中执行，会导致阻塞;
  - **bgsave**:创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是 Redis RDB 文件生成的默认配置。
- **快照时数据能修改吗**?
  - **避免阻塞和正常处理写操作并不是一回事**。此时，主线程的确没有阻塞，可以正常接收请求，但 是，为了保证快照完整性，它只能处理读操作，因为不能修改正在执行快照的数据。
  - 为了快照而暂停写操作，肯定是不能接受的。所以这个时候，Redis 就会借助操作系统提 供的**写时复制技术(Copy-On-Write, COW)**，在执行快照的同时，正常处理写操作。
    - 简单来说，bgsave 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据。 bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件。
    - 如果主线程对这些数据也都是读操作，那么，主线程和 bgsave 子进程相互不影响。但是，**如果主线程要修改一块数据， 那么，这块数据就会被复制一份，生成该数据的副本**。然后，bgsave 子进程会把这个副本 数据写入 RDB 文件，而在这个过程中，主线程仍然可以直接修改原来的数据。
- **可以每秒做一次快照吗?**
  - **如果频繁地执行全量 快照，也会带来两方面的开销**。
    - 一方面，频繁将全量数据写入**磁盘**，会给磁盘带来很大压力。
    - 另一方面，bgsave 子进程需要通过 fork 操作从主线程创建出来。虽然，子进程在创建后 不会再阻塞主线程，但是，**fork 这个创建过程本身会阻塞主线程**，而且主线程的内存越 大，阻塞时间越长。如果频繁 fork 出 bgsave 子进程，这就会频繁阻塞主线程了。
  - 此时，我们可以做增量快照，所谓增量快照，就是指，做了一次全量快照后，后续的快照只对修改的数据进行快照记录，这样可以避免每次全量快照的开销。
    - 为了“记住”修改，引入的 额外空间开销比较大。这对于内存资源宝贵的 Redis 来说，有些得不偿失。
- 虽然跟 AOF 相比，快照的恢复速度快，但是，快照的频率不好把 握，如果频率太低，两次快照间一旦宕机，就可能有比较多的数据丢失。如果频率太高， 又会产生额外开销，那么，**还有什么方法既能利用 RDB 的快速恢复，又能以较小的开销做 到尽量少丢数据呢?**
  - **Redis 4.0** 中提出了一个**混合使用 AOF 日志和内存快照**的方法。简单来说，内存快照以一 定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。
- 最后，关于 AOF 和 RDB 的选择问题，我想再给你提三点建议:
  - 数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择; 
  - 如果允许分钟级别的数据丢失，可以只使用 RDB;
  - 如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个 平衡。









# **数据同步**

-  Redis 具有高可靠性
  - 其实，这里有两层含义:一是**数据尽量少丢失**，二是**服务尽量少中断**。
  - AOF 和 RDB 保证了前者，而对于后者，Redis 的做法就是**增加副本冗余量**，将一份数据同时保存在多个实例上。
    - 实际上，Redis 提供了主从库模式，以保证数据副本的一致，主从库之间采用的是读写分离的方式。
- 主从库间如何进行第一次同步?
  - 当我们启动多个 Redis 实例的时候，它们相互之间就可以通过 **replicaof(Redis 5.0 之前 使用 slaveof)命令形成主库和从库的关系，之后会按照三个阶段完成数据的第一次同步。**
- **主从库间数据第一次同步的三个阶段**
  - 第一阶段是主从库间建立连接、协商同步的过程，主要是为全量复制做准备。在这一步，**从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开 始同步了**。
    - 具体来说，**从库给主库发送 psync 命令**，表示要进行数据同步，主库根据这个命令的参数 来启动复制。psync 命令包含了**主库的 runID** 和**复制进度 offset** 两个参数。
      - runID，是每个 Redis 实例启动时都会自动生成的一个随机 ID，用来唯一标记这个实 例。当从库和主库第一次复制时，因为不知道主库的 runID，所以将 runID 设 为“?”。
      - offset，此时设为 -1，表示第一次复制。
    - **主库收到 psync 命令后，会用 FULLRESYNC 响应命令带上两个参数**:主库 runID 和主库 目前的复制进度 offset，返回给从库。从库收到响应后，会记录下这两个参数。
      - **FULLRESYNC 响应表示第一次复制采用的全量复制，也就是说， 主库会把当前所有的数据都复制给从库**。
  - 在第二阶段，**主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载**。这个 过程依赖于内存快照生成的 RDB 文件。
    - 具体来说，**主库执行 bgsave 命令**，生成 RDB 文件，接着将文件发给从库。从库接收到 RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。这是因为从库在通过 replicaof 命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把 当前数据库清空。
    - 在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求。否则， Redis 的服务就被中断了。但是，这些请求中的写操作并没有记录到刚刚生成的 RDB 文件 中。**为了保证主从库的数据一致性，主库会在内存中用专门的 replication buffer，记录 RDB 文件生成后收到的所有写操作。**
  - 第三个阶段，**主库会把第二阶段执行过程中新收到的写命令，再发送给从 库。**具体的操作是，当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修 改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了。
- **主从级联模式分担全量复制时的主库压力**
  - **一次全量复制中，对于主库来 说，需要完成两个耗时的操作:生成 RDB 文件和传输 RDB 文件。**
  - 在刚才介绍的主从库模式中，所有的从库都是和主库连接，所有的全量复制也都是和主库 进行的。现在，我们可以**通过“主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力， 以级联的方式分散到从库上**。
    - 简单来说，我们在部署主从集群的时候，可以手动选择一个从库(比如选择内存资源配置较高的从库)，用于级联其他的从库。然后，我们可以再选择一些从库(例如三分之一的从库)，在这些从库上执行如下命令，让它们和刚才所选的从库，建立起主从关系。
    - 这样一来，这些从库就会知道，在进行同步时，不用再和主库进行交互了，只要和级联的从库进行写操作同步就行了，这就可以减轻主库上的压力
  - 听上去好像很简单，但不可忽视的是，这个过程中存在着风险点，最常见的就是**网络断连或阻塞**。如果网络断连，主从库之间就无法进行命令传播了，从库的数据自然也就没办法 和主库保持一致了，客户端就可能从从库读到旧数据。
- **主从库间网络断了怎么办?**
  - 从 Redis 2.8 开始，网络断了之后，主从库会采用增量复制的方式继续同步。听名字大概 就可以猜到它和全量复制的不同:全量复制是同步所有数据，而**增量复制**只会把主从库网 络断连期间主库收到的命令，同步给从库。
  - 当主从库断连后，主库会把断连期间收到的写操作命令，写入 replication buffer，同时也 会把这些操作命令也写入 **repl_backlog_buffer** 这个缓冲区。
    - repl_backlog_buffer 是一个环形缓冲区，**主库会记录自己写到的位置，从库则会记录自己 已经读到的位置**。
    - 刚开始的时候，主库和从库的写读位置在一起，这算是它们的起始位置。随着主库不断接 收新的写操作，它在缓冲区中的写位置会逐步偏离起始位置，我们通常用偏移量来衡量这 个偏移距离的大小，对主库来说，对应的偏移量就是 **master_repl_offset**。主库接收的新 写操作越多，这个值就会越大。
    - 主从库的连接恢复之后，从库首先会给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库，主库会判断自己的 master_repl_offset 和 slave_repl_offset 之间的差距。此时，主库只用把 master_repl_offset 和 slave_repl_offset 之间的命令操作同步给从库就行。
  - 强调一下，因为 repl_backlog_buffer 是一个环形缓冲区，所以在 缓冲区写满后，主库会继续写入，此时，就会覆盖掉之前写入的操作。**如果从库的读取速 度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库 间的数据不一致**
    - 因此，我们要想办法避免这一情况，一般而言，我们可以调整 **repl_backlog_size** 这个参数。这个参数和所需的缓冲空间大小有关。缓冲空间的计算公式是:缓冲空间大小 = 主库 写入命令速度 * 操作大小 - 主从库间网络传输命令速度 * 操作大小。在实际应用中，考虑 到可能存在一些突发的请求压力，我们通常需要把这个缓冲空间扩大一倍，即 **repl_backlog_size = 缓冲空间大小 * 2，这也就是 repl_backlog_size 的最终值。**
  - 这样一来，增量复制时主从库的数据不一致风险就降低了。不过，如果并发请求量非常大，连两倍的缓冲空间都存不下新操作请求的话，此时，主从库数据仍然可能不一致。
    - 针对这种情况，**一方面**，你可以根据 Redis 所在服务器的内存资源再适当增加 repl_backlog_size 值，比如说**设置成缓冲空间大小的 4 倍**，**另一方面**，你可以考虑使用**切片集群**来分担单个主库的请求压力。







# **哨兵机制**

- **哨兵机制的基本流程**
  - 哨兵其实就是一个运行在特殊模式下的 Redis 进程，主从库实例运行的同时，它也在运 行。哨兵主要负责的就是三个任务:**监控、选主(选择主库)和通知。**
  - **监控**是指哨兵进程在运行时，**周期性地给所有的主从库发送 PING 命令， 检测它们是否仍然在线运行**。如果从库没有在规定时间内响应哨兵的 PING 命令，哨兵就 会把它标记为“下线状态”;同样，如果主库也没有在规定时间内响应哨兵的 PING 命 令，哨兵就会判定主库下线，然后开始**自动切换主库**的流程。
  - **这个流程首先是执行哨兵的第二个任务：选主**。主库挂了以后，哨兵就需要从很多个从库里，按照一定的规则选择一个从库实例，把它作为新的主库。这一步完成后，现在的集群里就有了新主库。
  - **然后，哨兵会执行最后一个任务：通知**。在执行通知任务时，哨兵会把新主库的连接信息 发给其他从库，让它们执行 replicaof 命令，和新主库建立连接，并进行数据复制。同时， 哨兵会把新主库的连接信息通知给客户端，让它们把请求操作发到新主库上。
- 在监控和选主这两个任务中，哨兵需要做出两个决策:
  - 在监控任务中，哨兵需要判断主库是否处于下线状态;
  - 在选主任务中，哨兵也要决定选择哪个从库实例作为主库。
- **主观下线和客观下线**
  - 如果哨兵发现主库或从库对 PING 命令的响应超时了，那么，哨兵就会先把它标记 为“主观下线”。
    - 如果检测的是从库，那么，哨兵简单地把它标记为“主观下线”就行了，因为从库的下线影响一般不太大，集群的对外服务不会间断。
    - **但是，如果检测的是主库，那么，哨兵还不能简单地把它标记为“主观下线”，开启主从切换**。因为很有可能存在这么一个情况:那就是哨兵误判了，其实主库并没有故障。可是，一旦启动了主从切换，后续的选主和通知操作都会带来额外的计算和通信开销。
  - 为了避免这些不必要的开销，我们要特别注意误判的情况。
    - 我们要知道啥叫误判。很简单，就是主库实际并没有下线，但是哨兵误以为它下线了。误判一般会发生在集群网络压力较大、网络拥塞，或者是主库本身压力较大的情况下。
    - 哨兵机制也是类似的，它**通常会采用多实例组成的集群模式进行部署，这也被称为哨兵集群**。引入多个哨兵实例一起来判断，就可以避免单个哨兵因为自身网络状况不好，而误判主库下线的情况。
  - 简单来说，“客观下线”的标准就是，当有 N 个哨兵实例时，最好要有 N/2 + 1 个实例判 断主库为“主观下线”，才能最终判定主库为“客观下线”。
- **如何选定新主库?**
  - 一般来说，我把哨兵选择新主库的过程称为“筛选 + 打分”。简单来说，我们在多个从库 中，先按照**一定的筛选条件**，把不符合条件的从库去掉。然后，我们再按照**一定的规则**， 给剩下的从库逐个打分，将得分最高的从库选为新主库。
  - 一般情况下，我们肯定要先保证所选的从库仍然在线运行。不过，在选主时从库正常在线，这只能表示从库的现状良好，并不代表它就是最适合做主库的。
    - 所以，在选主时，**除了要检查从库的当前在线状态，还要判断它之前的网络连接状态**。如 果从库总是和主库断连，而且断连次数超出了一定的阈值，我们就有理由相信，这个从库 的网络状况并不是太好，就可以把这个从库筛掉了。
    - 具体怎么判断呢?你使用配置项 down-after-milliseconds * 10。其中，**down-after- milliseconds 是我们认定主从库断连的最大连接超时时间。**如果在 down-after- milliseconds 毫秒内，主从节点都没有通过网络联系上，我们就可以认为主从节点断连 了。如果发生断连的次数超过了 10 次，就说明这个从库的网络状况不好，不适合作为新主 库。
  - 我们可以分别按照三个规则依次进行三轮打分，这三个 规则分别是**从库优先级、从库复制进度以及从库 ID 号**。只要在某一轮中，有从库得分最 高，那么它就是主库了，选主过程到此结束。如果没有出现得分最高的从库，那么就继续 进行下一轮。
    - 第一轮:优先级最高的从库得分高。
      - 用户可以通过 slave-priority 配置项，给不同的从库设置不同优先级
    - 第二轮:和旧主库同步程度最接近的从库得分高。
      - 主从库同步时有个命令传播的过程。在这个过程中，主库会用 master_repl_offset 记录当前的最新写操作在 repl_backlog_buffer 中的位置，而从库会 用 slave_repl_offset 这个值记录当前的复制进度。
      - 有从库的 slave_repl_offset 最接近 master_repl_offset，那么它的得分就 最高，可以作为新主库。
      - **实际的选主代码层面，sentinel是直接比较从库的slave_repl_offset，来选择和主库最接近的从库。哨兵在这一步，是 通过比较不同从库的slave_repl_offset，找出最大slave_repl_offset的从库。**
    - 第三轮:ID 号小的从库得分高。
      - 目前，Redis 在选主库 时，有一个默认的规定:**在优先级和复制进度都相同的情况下，ID 号最小的从库得分最 高，会被选为新主库**。







# **哨兵集群**

- 实际上，一旦多个实例组成了**哨兵集群**，即使有哨兵实例出现故障挂掉了，其他哨兵还能 继续协作完成主从库切换的工作，包括判定主库是不是处于下线状态，选择新主库，以及 通知从库和客户端。
- **基于** **pub/sub机制的哨兵集群组成**
  - 哨兵只要和主库建立起了连接，就可以在主库上发布消息了，比如说发布它自己的连接信 息(IP 和端口)。同时，它也可以从主库上订阅消息，获得其他哨兵发布的连接信息。当 多个哨兵实例都在主库上做了发布和订阅操作后，它们之间就能知道彼此的 IP 地址和端 口。
  - 在主从集群中，主库上有一个名为“__sentinel__:hello”的频道，不同哨兵就是通过 它来相互发现，实现互相通信的。
- **哨兵是如何知道从库的 IP 地址和端口的呢**
  - **这是由哨兵向主库发送 INFO 命令来完成的。**哨兵 2 给主库发送 INFO 命 令，主库接受到这个命令后，就会把从库列表返回给哨兵。接着，哨兵就可以根据从库列 表中的连接信息，和每个从库建立连接，并在这个连接上持续地对从库进行监控。哨兵 1 和 3 可以通过相同的方法和从库建立连接。
  - 但是，哨兵不能只和主、从库连接。因为，主从库切换后，客户端也需要知道新主库的连接信息，才能向新主库发送请求操作。所以，哨兵还需要完成把新主库的信息告诉客户端这个任务。
- **基于** **pub/sub** **机制的客户端事件通知**
  - **我们仍然可以依赖 pub/sub 机制，来帮助我们完成哨兵和客户端间的信息同步。**
  - 重要的频道汇总在了一起，涉及几个关键事件，包括主库下线判断、新主库选定、从库重新配置。
    - 知道了这些频道之后，你就可以**让客户端从哨兵这里订阅消息**了。具体的操作步骤是，客 户端读取哨兵的配置文件后，可以获得哨兵的地址和端口，和哨兵建立网络连接。然后， 我们可以在客户端执行订阅命令，来获取不同的事件消息。
    - 有了这些事件通知，客户端不仅可以在主从切换后得到新主库的连接信息，还可以监控到主从库切换过程中发生的各个重要事件。这样，客户端就可以知道主从切换进行到哪一步了，有助于了解切换进度。
- **由哪个哨兵执行主从切换?**
  - **任何一个实例只要自身判断主库“主观下线”后，就会给其他实例发送 is-master-down- by-addr 命令。**接着，其他实例会根据自己和主库的连接情况，做出 Y 或 N 的响应，Y 相 当于赞成票，N 相当于反对票。
  - 此时，这个哨兵就可以再给其他哨兵发送命令，表明希望由自己来执行主从切换，并让所 有其他哨兵进行投票。这个投票过程称为“Leader 选举”。因为最终执行主从切换的哨兵 称为 Leader，投票过程就是确定 Leader。
- **分享一个经验：要保证所有哨兵实例的配置是一致的，尤其是主观下线的判断值 down-after-milliseconds**。
  - 调大down-after-milliseconds值，对减少误判是不是有好处？
    - 是有好处的，适当调大down-after-milliseconds值，当哨兵与主库之间网络存在短时波动时，可以降低误判的概率。但是调大down-after-milliseconds值也意味着主从切换的时间会变长，对业务的影响时间越久，我们需要根据实际场景进行权衡，设置合理的阈值。









# **切片集群**

- 这么一个需求:要用 Redis 保存 5000 万个键值对，每个键值对大约是 512B， 为了能快速部署并对外提供服务，我们采用云主机来运行 Redis 实例，那么，该如何选择 云主机的内存容量呢?
  - 在使用 RDB 进行持久化时，Redis 会 fork 子进程来完 成，**fork 操作的用时和 Redis 的数据量是正相关的**，而 fork 在执行时会阻塞主线程。数 据量越大，fork 操作造成的主线程阻塞的时间越长。所以，在使用 RDB 对 25GB 的数据 进行持久化时，数据量较大，后台运行的子进程在 fork 创建时阻塞了主线程，于是就导致 Redis 响应变慢了。
  - 必须要寻找其他的方案：虽然组建切片集群比较麻烦，但是它可以保存大量数据，而且对 Redis 主线程的阻塞影响较小。
    - 切片集群，也叫分片集群，就是指启动多个 Redis 实例组成一个集群，然后按照一定的规 则，把收到的数据划分成多份，每一份用一个实例来保存。回到我们刚刚的场景中，如果 把 25GB 的数据平均分成 5 份(当然，也可以不做均分)，使用 5 个实例来保存，每个实 例只需要保存 5GB 数据。
- **如何保存更多数据?**
  - 在刚刚的案例里，为了保存大量数据，我们使用了大内存云主机和切片集群两种方法。实 际上，这两种方法分别对应着 Redis 应对数据量增多的两种方案:纵向扩展(scale up) 和横向扩展(scale out)。
    - **纵向扩展**:升级单个 Redis 实例的资源配置，包括增加内存容量、增加磁盘容量、使用 更高配置的 CPU。
    - **横向扩展**:横向增加当前 Redis 实例的个数
  - 首先，纵向扩展的好处是，**实施起来简单、直接**。不过，这个方案也面临两个潜在的问 题。
    - 第一个问题是，当使用 RDB 对数据进行持久化时，如果数据量增加，需要的内存也会增 加，主线程 fork 子进程时就可能会阻塞(比如刚刚的例子中的情况)。不过，如果你不要 求持久化保存 Redis 数据，那么，纵向扩展会是一个不错的选择。
    - 不过，这时，你还要面对第二个问题:**纵向扩展会受到硬件和成本的限制**。这很容易理 解，毕竟，把内存从 32GB 扩展到 64GB 还算容易，但是，要想扩充到 1TB，就会面临硬 件容量和成本上的限制了。
  - **在面向百万、千万级别的用户规模时，横向扩展的 Redis 切片集群会是一个非常好 的选择**。
  - 要想把切片集群用起来，我们就需要解决两大问题:
    - 数据切片后，在多个实例之间如何分布?
    - 客户端怎么确定想要访问的数据在哪个实例上?
- **数据切片和实例的对应分布关系**
  - 具体来说，Redis Cluster 方案采用哈希槽(Hash Slot，接下来我会直接称之为 Slot)， 来处理数据和实例之间的映射关系。在 Redis Cluster 方案中，一个切片集群共有 16384 个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈 希槽中。
  - 具体的映射过程分为两大步:首先根据键值对的 key，按照CRC16 算法计算一个 16 bit 的值;然后，再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。
  - 我们在部署 Redis Cluster 方案时，可以使用 cluster create 命令创建集群，此时，Redis 会自动把这些槽平均分布在集群实例上。例如，如果集群中有 N 个实例，那么，每个实例 上的槽个数为 16384/N 个。
    - 当然， 我们也可以使用 cluster meet 命令手动建立实例间的连接，形成集群，再使用 cluster addslots 命令，指定每个实例上的哈希槽个数。
    - **在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作**。
- **客户端如何定位数据?**
  - 客户端收到哈希槽信息后，会把哈希槽信息缓存在本地。当客户端请求键值对时，会先计算键所对应的哈希槽，然后就可以给相应的实例发送请求了。
  - 但是，在集群中，实例和哈希槽的对应关系并不是一成不变的，最常见的变化有两个:
    - 在集群中，实例有新增或删除，Redis 需要重新分配哈希槽; 
    - 为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。
  - 此时，实例之间还可以通过相互传递消息，获得最新的哈希槽分配信息，但是，客户端是无法主动感知这些变化的。这就会导致，它缓存的分配信息和最新的分配信息就不一致了，那该怎么办呢?
    - Redis Cluster 方案提供了一种**重定向机制，**所谓的“重定向”，就是指，客户端给一个实 例发送数据读写操作时，这个实例上并没有相应的数据，客户端要再给一个新实例发送操 作命令。
    - 当客户端把一个键值对的操作请 求发给一个实例时，如果这个实例上并没有这个键值对映射的哈希槽，那么，这个实例就 会给客户端返回下面的 MOVED 命令响应结果，这个结果中就包含了新实例的访问地址。
  - 在**迁移部分完成的情况**下，客户端就会收到一条 ASK 报错信息，如下所 示:
    - 这个结果中的 ASK 命令就表示，客户端请求的键值对所在的哈希槽 13320，在 172.16.19.5 这个实例上，但是这个哈希槽正在迁移。此时，客户端需要先给 172.16.19.5 这个实例发送一个 ASKING 命令。这个命令的意思是，让这个实例允许执行客户端接下来 发送的命令。然后，客户端再向这个实例发送 GET 命令，以读取数据。
    - ASK 命令表示两层含义:第一，表明 Slot 数据还在迁移中;第二，ASK 命令把客户端所 请求数据的最新实例地址返回给客户端，此时，客户端需要给实例 3 发送 ASKING 命令， 然后再发送操作命令。
    - 和 MOVED 命令不同，**ASK 命令并不会更新客户端缓存的哈希槽分配信息**。所以，在上图 中，如果客户端再次请求 Slot 2 中的数据，它还是会给实例 2 发送请求。这也就是说， ASK 命令的作用只是让客户端能给新实例发送一次请求，而不像 MOVED 命令那样，会更 改本地缓存，让后续所有命令都发往新实例。





# String

- String 类型并不是适用于所有场合的，它有 一个明显的短板，就是它保存数据时所消耗的内存空间较多。
  - 集合类型有非常节省内存空间的底 层实现结构，但是，集合类型保存的数据模式，是一个键对应一系列值，并不适合直接保 存单值的键值对。所以，使用二级编码的方法，实现了用集合类型保存单值键值对，Redis 实例的内存空间消耗明显下降了。
- **为什么** **String类型内存开销大?**
  - 除了记录实际数据，String 类型还需要额外的内存空间记录数据长度、空间使用等 信息，这些信息也叫作元数据。当实际保存的数据较小时，元数据的空间开销就显得比较 大了，有点“喧宾夺主”的意思。
  - 当你保存的数据中包含字符时，String 类型就会用简单动态字符串(Simple Dynamic String，SDS)结构体来保存
  - 另外，**对于 String 类型来说，除了 SDS 的额外开销，还有一个来自于 RedisObject 结构 体的开销。**
  - 因为 Redis 的数据类型有很多，而且，不同数据类型都有些相同的元数据要记录(比如最 后一次访问的时间、被引用的次数等)，所以，Redis 会用一个 RedisObject 结构体来统 一记录这些元数据，同时指向实际数据。
    - 一方面，当保存的是 Long 类型整数时，RedisObject 中的指针就直接赋值为整数数据 了，这样就不用额外的指针再指向整数了，节省了指针的空间开销。
    - 另一方面，当保存的是字符串数据，并且字符串小于等于 44 字节时，RedisObject 中的元 数据、指针和 SDS 是一块连续的内存区域，这样就可以避免内存碎片。这种布局方式也被 称为 embstr 编码方式。
    - 当然，当字符串大于 44 字节时，SDS 的数据量就开始变多了，Redis 就不再把 SDS 和 RedisObject 布局在一起了，而是会给 SDS 分配独立的空间，并用指针指向 SDS 结构。 这种布局方式被称为 raw 编码模式。
  - 因为 10 位数的图片 ID 和图片存储对象 ID 是 Long 类型整数，所以可以直接用 int 编码 的 RedisObject 保存。每个 int 编码的 RedisObject 元数据部分占 8 字节，指针部分被直 接赋值为 8 字节的整数了。此时，每个 ID 会使用 16 字节，加起来一共是 32 字节。但 是，另外的 32 字节去哪儿了呢?
    - Redis 会使用一个全局哈希表保存所有键值对，哈希表的每一项是 一个 dictEntry 的结构体，用来指向一个键值对。dictEntry 结构中有三个 8 字节的指针， 分别指向 key、value 以及下一个 dictEntry，三个指针共 24 字节
    - 但是，这三个指针只有 24 字节，为什么会占用了 32 字节呢?这就要提到 Redis 使用的内 存分配库 jemalloc 了。
    - jemalloc 在分配内存时，会根据我们申请的字节数 N，找一个比 N 大，但是最接近 N 的 2 的幂次数作为分配的空间，这样可以减少频繁分配的次数。
    - 举个例子。如果你申请 6 字节空间，jemalloc 实际会分配 8 字节空间;如果你申请 24 字 节空间，jemalloc 则会分配 32 字节。所以，在我们刚刚说的场景里，dictEntry 结构就占 用了 32 字节。
- **用什么数据结构可以节省内存?**
  - Redis 有一种底层数据结构，叫**压缩列表(ziplist)**，这是一种非常节省内存的结构。
  - 压缩列表的构成。表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长 度、列表尾的偏移量，以及列表中的 entry 个数。压缩列表尾还有一个 zlend，表示列表 结束。
  - 压缩列表之所以能节省内存，就在于它是用一系列连续的 entry 保存数据。
  - 每个 entry 的 元数据包括下面几部分。
    - **prev_len**，表示前一个 entry 的长度。prev_len 有两种取值情况:1 字节或 5 字节。 取值 1 字节时，表示上一个 entry 的长度小于 254 字节
    - **len**:表示自身长度，4 字节; 
    - **encoding**:表示编码方式，1 字节; 
    - **content**:保存实际数据。
  - 这些 entry 会挨个儿放置在内存中，不需要再用额外的指针进行连接，这样就可以节省指 针所占用的空间。
  - 我们以保存图片存储对象 ID 为例，来分析一下压缩列表是如何节省内存空间的。
    - 每个 entry 保存一个图片存储对象 ID(8 字节)，此时，每个 entry 的 prev_len 只需要 1 个字节就行，因为每个 entry 的前一个 entry 长度都只有 8 字节，小于 254 字节。这样一来，一个图片的存储对象 ID 所占用的内存大小是 14 字节(1+4+1+8=14)，实际分 配 16 字节。
    - Redis 基于压缩列表实现了 List、Hash 和 Sorted Set 这样的集合类型，这样做的最大好 处就是节省了 dictEntry 的开销。当你用 String 类型时，一个键值对就有一个 dictEntry， 要用 32 字节空间。但采用集合类型时，一个 key 就对应一个集合的数据，能保存的数据 多了很多，但也只用了一个 dictEntry，这样就节省了内存。
- **如何用集合类型保存单值的键值对?**
  - 在保存单值的键值对时，可以采用基于 Hash 类型的二级编码方法。这里说的二级编码， 就是把一个单值的数据拆分成两部分，前一部分作为 Hash 集合的 key，后一部分作为 Hash 集合的 value，这样一来，我们就可以把单值数据保存到 Hash 集合中了。
    - 以图片 ID 1101000060 和图片存储对象 ID 3302000080 为例，我们可以把图片 ID 的前 7 位(1101000)作为 Hash 类型的键，把图片 ID 的最后 3 位(060)和图片存储对象 ID 分别作为 Hash 类型值中的 key 和 value。
  - **二级编码方法中采用的 ID 长度是有讲 究的**。
    - Hash 类型底层结构什么时候使用压缩列表，什么时候使用哈希表呢?其实，Hash 类型设置了用压缩列表保存数据时的两个阈值，一旦超过了阈值，Hash 类型就会用哈希表 来保存数据了。
    - 两个阈值分别对应以下两个配置项:
      - hash-max-ziplist-entries:表示用压缩列表保存时哈希集合中的最大元素个数。 
      - hash-max-ziplist-value:表示用压缩列表保存时哈希集合中单个元素的最大长度
  - 一旦从压缩列表转为了哈希表，Hash 类型就会一直用哈希表进行保存，而不会再转回压缩 列表了。在节省内存空间方面，哈希表就没有压缩列表那么高效了。
  - **为了能充分使用压缩列表的精简内存布局，我们一般要控制保存在 Hash 集合中的元素个 数**。所以，在刚才的二级编码中，我们只用图片 ID 最后 3 位作为 Hash 集合的 key，也就 保证了 Hash 集合的元素个数不超过 1000，同时，我们把 hash-max-ziplist-entries 设置 为 1000，这样一来，Hash 集合就可以一直使用压缩列表来节省内存空间了。





# **集合统计模式**

- **要想选择合适的集合，我们就得了解常用的集合统计模式。**这节课，我就给你介绍集合类 型常见的四种统计模式，包括聚合统计、排序统计、二值状态统计和基数统计
- **聚合统计**
  - 所谓的聚合统计，就是指统计多个集合元素的聚合结果，包括:统计多个集合的共有元素(交集统计);把两个集合相比，统计其中一个集合独有的元素(差集统计);统计多个集合的所有元素(并集统计)。
  - 当你需要对多个集合进行聚合计算时，Set 类型会是一个非常不错的选择。不过，我要提醒 你一下，这里有一个潜在的风险。
  - Set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计 算，会导致 Redis 实例阻塞。所以，我给你分享一个小建议:**你可以从主从集群中选择一 个从库，让它专门负责聚合计算，或者是把数据读取到客户端，在客户端来完成聚合统 计**，这样就可以规避阻塞主库实例和其他从库实例的风险了。
- **排序统计**
  - **List 是按照元素进入 List 的顺序进行排序的，而 Sorted Set 可以根据元素的权重来排序**
  - 在面对需要展示最新列表、排行榜等场景时，如果数据更新频繁或者需要分页显示，建议你优先考虑使用 Sorted Set
- **二值状态统计**
  - 这里的二值状态就是指集合元素的取 值就只有 0 和 1 两种。
  - 在签到统计时，每个用户一天的签到用 1 个 bit 位就能表示，一个月(假设是 31 天)的签 到情况用 31 个 bit 位就可以，而一年的签到也只需要用 365 个 bit 位，根本不用太复杂 的集合类型。这个时候，我们就可以选择 Bitmap。
  - **Bitmap 本身是用 String 类型作为底层数据结构实现的一种统计二值状态的数据类型。** String 类型是会保存为二进制的字节数组，所以，Redis 就把字节数组的每个 bit 位利用 起来，用来表示一个元素的二值状态。**你可以把 Bitmap 看作是一个 bit 数组。**
  - 所以，如果只需要统计数据的二值状态，例如商品有没有、用户在不在等，就可以使用 Bitmap，因为它只用一个 bit 位就能表示 0 或 1。在记录海量数据时，Bitmap 能够有效 地节省内存空间。
- **基数统计**
  - 基数统计就是指统计一个集合中不重复的元 素个数。对应到我们刚才介绍的场景中，就是统计网页的 UV。
  - 网页 UV 的统计有个独特的地方，就是需要去重，一个用户一天内的多次访问只能算作一 次。在 Redis 的集合类型中，Set 类型默认支持去重，所以看到有去重需求时，我们可能 第一时间就会想到用 Set 类型。当然，你也可以用 Hash 类型记录 UV。
  - 但是，和 Set 类型相似，当页面很多时，Hash 类型也会消耗很大的内存空间。那么，有什 么办法既能完成统计，还能节省内存吗?
  - 这时候，就要用到 Redis 提供的 HyperLogLog 了。
    - HyperLogLog 是一种用于统计基数的数据集合类型，它的最大优势就在于，当集合元素数 量非常多时，它计算基数所需的空间总是固定的，而且还很小。
    - 不过，有一点需要你注意一下，**HyperLogLog 的统计规则是基于概率完成的，所以它给出 的统计结果是有一定误差**的，标准误算率是 0.81%。这也就意味着，你使用HyperLogLog 统计的 UV 是 100 万，但实际的 UV 可能是 101 万。虽然误差率不算大， 但是，如果你需要精确统计结果的话，最好还是继续用 Set 或 Hash 类型。







# **消息队列**

- **消息队列的消息存取需求**

  - 不过，消息队列在存取消息时，**必须要满足三个需求，分别是消息保序、处理重复的消息和保证消息可靠性。**
  - Redis 的 List 和 Streams 两种数据类型，就可以满足消息队列的这三个需求

- **基于** **Streams** **的消息队列解决方案**

  - Streams 是 Redis 专门为消息队列设计的数据类型，它提供了丰富的消息队列操作命令。

  - > XADD:插入消息，保证有序，可以自动生成全局唯一 ID;
    >
    > XREAD:用于读取消息，可以按 ID 读取数据;
    >
    > XREADGROUP:按消费组形式读取消息;
    >
    > XPENDING 和 XACK:XPENDING 命令可以用来查询每个消费组内所有消费者已读取 但尚未确认的消息，而 XACK 命令用于向消息队列确认消息处理已完成。

  - 消息队列中的消息一旦被消费组里的一个消费者读取了，就不能再被该消 费组内的其他消费者读取了。

- 相比 Redis 来说，Kafka 和 RabbitMQ 一般被认为是重量级的消息队列。









# **缓存异常**

- 缓存和数据库的数据不一致是如何发生的?

  - 这里的“一致性”包含了两种情况:
    - 缓存中有数据，那么，缓存的数据值需要和数据库中的值相同;
    - 缓存中本身没有数据，那么，数据库中的值必须是最新值。
  - 当缓存的读写模 式不同时，缓存数据不一致的发生情况不一样，我们的应对方法也会有所不同

- 对于读写缓存来说，如果要对数据进行增删改，就需要在缓存中进行，同时还要根据采取的写回策略，决定是否同步写回到数据库中。

  - **同步直写策略**:写缓存时，也同步写数据库，缓存和数据库中的数据一致;
  - **异步写回策略**:写缓存时不同步写数据库，等到数据从缓存中淘汰时，再写回数据库。使用这种策略时，如果数据还没有写回数据库，缓存就发生了故障，那么，此时，数据库就没有最新的数据了。

- 对于读写缓存来说，**要想保证缓存和数据库中的数据一致，就要采用同步直写策略**。不过，需要注意的是，**如果采用这种策略，就需要同时更新缓存和数据库。所以，我们要在业务应用中使用事务机制**，来保证缓存和数据库的更新具有**原子性**。

  - 当然，**在有些场景下，我们对数据一致性的要求可能不是那么高**，比如说缓存的是电商商品的非关键属性或者短视频的创建或修改时间等，那么，我们可以使用异步写回策略。

- 只读缓存

  - **对于只读缓存来说，如果有数据新增，会直接写入数据库;而有数据删改时，就需要把只读缓存中的数据标记为无效。**这样一来，应用后续再访问这些增删改的数据时，因为缓存中没有相应的数据，就会发生缓存缺失。此时，应用再从数据库中把数据读入缓存，这样后续再访问数据时，就能够直接从缓存中读取了。

- 写入和删改数据

  - **如果是新增数据**，数据会直接写到数据库中，不用对缓存做任何操作，此时，缓存中本身 就没有新增数据，而数据库中是最新值，这种情况符合我们刚刚所说的一致性的第 2 种情 况，所以，此时，缓存和数据库的数据是一致的。
  - 如果发生删改操作，应用既要更新数据库，也要在缓存中删除数据。这两个操作如果无法保证原子性，也就是说，要不都完成，要不都没完成，此时，就会出现数据不一致问题了

- 重试机制

  - **具体来说，可以把要删除的缓存值或者是要更新的数据库值暂存到消息队列中(例如使用 Kafka 消息队列)。**当应用没有能够成功地删除缓存值或者是更新数据库值时，可以从消 息队列中重新读取这些值，然后再次进行删除或更新。
  - 如果能够成功地删除或更新，我们就要把这些值从消息队列中去除，以免重复操作，此时，我们也可以保证数据库和缓存的数据一致了。否则的话，我们还需要再次进行重试。如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。
  - **实际上，即使这两个操作第一次执行时都没有失败，当有大量并发请求时，应用还是有可能读到不一致的数据。**

- **情况一:先删除缓存，再更新数据库。**

  - 假设线程 A 删除缓存值后，还没有来得及更新数据库(比如说有网络延迟)，线程 B 就开 始读取数据了，那么这个时候，线程 B 会发现缓存缺失，就只能去数据库读取。

    - 1. 线程 B 读取到了旧值;

      2. 线程 B 是在缓存缺失的情况下读取的数据库，所以，它还会把旧值写入缓存，这可能会 导致其他线程从缓存中读到旧值。

    - 等到线程 B 从数据库读取完数据、更新了缓存后，线程 A 才开始更新数据库，此时，缓存 中的数据是旧值，而数据库中的是最新值，两者就不一致了。

  - 解决方案

    - **在线程 A 更新完数据库值以后，我们可以让它先 sleep 一小段时间，再进行一次缓存删除 操作。**
    - 之所以要加上 sleep 的这段时间，就是为了让线程 B 能够先从数据库读取数据，再把缺失 的数据写入缓存，然后，线程 A 再进行删除。所以，线程 A sleep 的时间，就需要大于线 程 B 读取数据再写入缓存的时间。这个时间怎么确定呢?建议你在业务程序运行的时候， 统计下线程读数据和写缓存的操作时间，以此为基础来进行估算。
    - 这样一来，其它线程读取数据时，会发现缓存缺失，所以会从数据库中读取最新值。因为这个方案会在第一次删除缓存值后，延迟一段时间再次进行删除，所以我们也把它叫做“延迟双删”。

  - “延迟双删”方案的示例

    - ```sql
      redis.delKey(X) 
      db.update(X)
      Thread.sleep(N) 
      redis.delKey(X)
      ```

- **情况二:先更新数据库值，再删除缓存值。**

  - 如果线程 A 删除了数据库中的值，但还没来得及删除缓存值，线程 B 就开始读取数据了， 那么此时，线程 B 查询缓存时，发现缓存命中，就会直接从缓存中读取旧值。不过，在这 种情况下，**如果其他线程并发读缓存的请求不多，那么，就不会有很多请求读取到旧值。** 而且，线程 A 一般也会很快删除缓存值，这样一来，其他线程再次读取时，就会发生缓存 缺失，进而从数据库中读取最新值。所以，这种情况对业务的影响较小。

- 缓存和数据库的数据不一致一般是由两个原因导致的

  - 删除缓存值或更新数据库失败而导致数据不一致，你可以使用重试机制确保删除或更新操作成功。
  - 在删除缓存值、更新数据库的这两步操作中，有其他线程的并发读操作，导致其他线程读取到旧值，应对方案是延迟双删。





# **无锁的原子操作**

- **比如说如果多个用户同时下单，就会对缓存在 Redis 中的商品库存并发更新。一旦有了并发写操作，数据就会被修改**，如果我们没有对并发写请求做好控制，就可能导致数据被改错。
- 























