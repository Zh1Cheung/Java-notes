

# 概念

简单来说，持续交付就是通过提升软件交付效率、统一标准、规范流程、工具化等方式，来进一步提升软件研发效能，并解决软件研发进度不可控、版本混乱难控无法回滚和回溯、无法快速定位发布问题、研发团队互相等待互相依赖等等问题

**我们可以把 “持续交付”定义为“一套软件工程方法论和许许多多的最佳实践的集合”**

- 它的关注点可以概括为：持续集成构建、测试自动化和部署流水线。



# 持续集成、持续交付和持续部署

- 我们通常会把软件研发工作拆解，拆分成不同模块或不同团队后进行编码，编码完成后，进行集成构建和测试。这个从编码到构建再到测试的反复持续过程，就叫作“持续集成”。
- 持续集成”一旦完成，则代表产品处在一个可交付状态，但并不代表这是最优状态，还需要根据外部使用者的反馈逐步优化。
  - 这个在“持续集成”之后，获取外部对软件的反馈再通过“持续集成”进行优化的过程就叫作“持续交付”，它是“持续集成”的自然延续。
- 持续部署”就是将可交付产品，快速且安全地交付用户使用的一套方法和系统，它是“持续交付”的最后“一公里”



# 持续交付和 DevOps

- 你可以理清持续交付和 DevOps 的关系：

  - DevOps 的本质其实是一种鼓励协作的研发文化；

  - 持续交付与 DevOps 所追求的最终目标是一致的，即快速向用户交付高质量的软件产品；

  - DevOps 的概念比持续交付更宽泛，是持续交付的继续延伸；

  - 持续交付更专注于技术与实践，是 DevOps 的工具及技术实现。



# 代码分支策略

- GitHub Flow
  - GitHub Flow 是 GitHub 所使用的一种简单流程。该流程只使用 master 和特性分支，并借助 GitHub 的 pull request 功能。
  - 当需要修改时，从 master 分支创建一个新的分支，所有相关的代码修改都在新分支中进行。开发人员可以自由地提交代码和提交到远程仓库。
  - 当新分支中的代码全部完成之后，通过 GitHub 提交一个新的 pull request。团队中的其他人员会对代码进行审查，提出相关的修改意见。由持续集成服务器（如 Jenkins）对新分支进行自动化测试。当代码通过自动化测试和代码审查之后，该分支的代码被合并到 master分支。再从 master 分支部署到生产环境。
- GitLab Flow
  - GitLab Flow 针对不同的发布场景，在 GitHub Flow（特性分支加 master 分支）的基础上做了改良，额外衍生出了三个子类模型
  - 带生产分支
    - 不具备主干开发能力
    - 无法控制准确的发布时间，但又要求不停集成
  - 带环境分支
    - 不具备主干开发能力
    - 需要逐个通过各个测试环境验证
  - 带发布分支
    - 不具备主干开发能力
    - 需要对外发布和维护不同版本

- 国内互联网公司的选择
  - 比如，携程公司在 GitHub Flow 的基础上，通过自行研发的集成加速器（Light Merge）和持续交付 Paas 平台，一起完成集成和发布。
  - 再比如，阿里的 AoneFlow，采用的是主干分支、特性分支和发布分支三种分支类型，再加上自行研发的 Aone 协同平台，实现持续交付



# 依赖管理

- Maven 如何管理依赖
  - 第一原则： 最短路径优先原则。比如，A 依赖了 B 和 C，而 B 也依赖了 C，那么 Maven会使用 A 依赖的 C 的版本，因为它的路径是最短的
  - 第二原则： 第一声明优先原则。比如，A 依赖了 B 和 C，B 和 C 分别依赖了 D，那么Maven 会使用 B 依赖的 D 的版本，因为它是最先声明的





# 代码回滚

![avatar](https://alfredliukai.github.io//2019/10/04/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E6%80%BB%E7%BB%93%E4%B8%80/cd8.png)

- 三种典型回滚场景及回滚策略

  - 个人分支回滚
  - 集成分支上线前回滚
  - 集成分支上线后回滚

- 第一，个人分支回滚

  ```
  $ git checkout feature-x   
  $ git reset --hard  C3 的 HASH 值
  $ git push -f origin  feature-x
  ```

第二，集成分支上线前回滚
![avatar](https://alfredliukai.github.io//2019/10/04/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E6%80%BB%E7%BB%93%E4%B8%80/cd10.png)
假定走特性分支开发模式，上面的 commit 都是特性分支通过 merge request 合入 master 产生的 commit。
集成后，测试环境中发现 C4 和 C6 的功能有问题，不能上线，需马上回滚代码，以便 C5 的功能上线。
团队成员可以在 GitLab 上找到 C4 和 C6 合入 master 的合并请求，然后点击 revert 。如下图所示。
![avatar](https://alfredliukai.github.io//2019/10/04/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E6%80%BB%E7%BB%93%E4%B8%80/cd11.png)
回滚后 master 分支变成如图 5 所示，C4’是 revert C4 产生的 commit，C6’是 revert C6 产生的 commit。通过 revert 操作，C4 和 C6 变更的内容在 master 分支上就被清除掉了，而 C5 变更的内容还保留在 master 分支上。
![avatar](https://alfredliukai.github.io//2019/10/04/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E6%80%BB%E7%BB%93%E4%B8%80/cd12.png)
第三，集成分支上线后回滚
![avatar](https://alfredliukai.github.io//2019/10/04/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E6%80%BB%E7%BB%93%E4%B8%80/cd13.png)
C3 打包并上线，生成线上的版本 V0529，运行正确。之后 C6 也打包并上线，生成线上版本 V0530，运行一段时间后发现有问题。C4 和 C5 并没有单独打包上线，所以没有对应的线上版本。
项目组把产品包从 V0530 回滚到 V0529，经过定位，V0530 的代码有问题，但短时间不能修复，于是，项目组决定回滚代码。
C4 和 C5 没有单独上过线，因此从线上包的角度看，不能回滚到 C4 或 C5，应该回滚到 C3。
考虑到线上包可以回滚到曾发布过的任意一个正确的版本。为了适应线上包的这个特点，线上包回滚触发的代码回滚我们决定不用 一个个 revert C4、C5 和 C6 的方式，而是直接创建一个新的 commit，它的内容等于 C3 的内容。

```
$ git fetch origin  
$ git checkout master
$ git reset --hard  V0529         # 把本地的 master 分支的指针回退到 V0529，此时暂存区 (index) 里就指向 V0529 里的内容了。
$ git reset --soft  origin/master  # --soft 使得本地的 master 分支的指针重新回到 V0530，而暂存区 (index) 变成 V0529 的内容。
$ git commit -m "rollback to V0529"  # 把暂存区里的内容提交，这样一来新生成的 commit 的内容和 V0529 相同。 
$ git push origin  master        # 远端的 master 也被回滚。
```

回滚后如下图所示。
![avatar](https://alfredliukai.github.io//2019/10/04/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E6%80%BB%E7%BB%93%E4%B8%80/cd14.png)
C3’的内容等于 C3，master 分支已清除 C4、C5 和 C6 的变更。
现在 master 又回到了正确的状态，其他功能可以继续上线。
如果要修复 C4、C5 和 C6 的问题，可以在开发分支上先 revert 掉 C3’ ，这样被清除的几个 commit 的内容又恢复了。





# 容器技术

- 重新定义交付标准
  - 容器技术统一了软件环境和软件代码，交付产物中既包括了软件环境，又包括了软件代码。也就是说，容器帮我们重新定义了交付标准
  - 第一，交付结果一致
    - 容器镜像可以把软件的运行环境以及代码打包在一起，因此可以基于同一个镜像，在不同的地方生成一模一样的运行环境，也就是说单个镜像的交付结果不可变
  - 第二，交付自动化
    - CI 方面，与传统方式的不同只在于，原先交付的是安装包或软件包，而容器交付的则是镜像
    - CD 方面，容器技术唯一的方式就是拉起容器镜像。这就大大简化了部署的复杂度，而且在编排系统的支持下，完成 CD 越来越容易了
  - 第三，交付个性化
    - 有了容器之后，我们可以使用统一的接口完成任何应用的部署，几乎可以很好地满足所有的个性化需求
  - 第四，交付版本控制
    - 对于容器来说，遵循的是不可变基础设施（Immutable Infrastructure）的理念，也就是说任何变化，包括代码、环境、配置的变更，都需要重新制作镜像，产生一个新的版本。

# 持续交付中有哪些宝贵数据

- 系统的稳定性（业务系统的稳定性评估方案）

  - 首先，我们通过监控、保障、人为记录等手段，统计所有的故障时间。需要统计的指标包括：开始时间、结束时间和故障时长。
  - 然后，计算过去三个月内这个时间段产生的持续交付平均业务量。所谓业务量，就是这个时间段内，处理的代码提交、code review；进行的编译、代码扫描、打包；测试部署；环境处理；测试执行和生产发布的数量。
  - 最后，计算这个时间段内的业务量与月平均量相比的损失率。这个损失率，就代表了系统的不稳定性率，反之就是稳定性率了。

- 把需要关注的系统指标数据做分类处理

  - 稳定性相关指标

    - 作为基础服务，稳定性是我们的生命线。所以，对于所有的子系统，包括：代码管理平台、集成编译系统、环境管理系统、测试管理系统和发布系统，我们都会设立必要的稳定性指标，并进行数据监控。这些稳定性相关的数据指标，代表整个系统的可用度

  - 性能相关指标

    > push 和 fetch 代码的速度；
    >
    > 环境创建和销毁的速度；
    >
    > 产生仿真数据的速度；
    >
    > 平均编译速度及排队时长；
    >
    > 静态检查的速度；
    >
    > 自动化测试的耗时；
    >
    > 发布和回滚的速度

  - 持续交付能力成熟度指标
    - 与代码管理子系统相关的指标包括：commit 的数量，code review 的拒绝率，并行开发的分支数量。
    - 与环境管理子系统相关的指标包括：计算资源的使用率，环境的平均大小。这里需要注意的是，我一直都很关注环境的平均大小这个数据。
    - 与集成编译子系统相关的指标包括：每日编译数量，编译检查的数据。我们并不会强制要求编译检查出的不良数据要下降，因为它会受各类外部因素的影响，比如历史代码问题等等。但，我们必须保证它不会增长。
    - 与测试管理子系统相关的指标包括：单元测试的覆盖率，自动化测试的覆盖率。这两个覆盖率代表了组织通过技术手段保证质量的能力，也是测试团队最常采用的数据指标。
    - 与发布管理子系统相关的指标包括：周发布数量，回滚比率。



# 构建持续交付系统

- GitLab 解决代码管理问题
- Jenkins 解决集成打包问题
- Ansible 解决自动部署问题
- 如何选择开源的 Docker 交付平台。
  - 如果你还没有在持续交付平台中支持 Kubernetes的话，我的建议是：直接考虑搭建持续交付平台 Spinnaker
  - Spinnaker 是 Netflix 的开源项目，致力于解除持续交付平台和云平台之间的耦合。这个持续交付平台的优点，主要包括：
    - 发布支持多个云平台，比如 AWS EC2、Microsoft Azure、Kubernetes 等。如果你未来有在多数据中心使用混合云的打算，Spinnaker 可以给你提供很多帮助。
    - 支持集成多个持续集成平台，包括 Jenkins、Travis CI 等。 
    - Netflix 是金丝雀发布的早期实践者，Spinnaker 中已经天然集成了蓝绿发布和金丝雀发布这两种发布策略，减少了开发发布系统的工作量。



# 如何基于K8s构建下一代DevOps平台



> OAM是阿里巴巴与微软联合推出的开放应用模型，旨在解耦应用研发、应用运维与基础设施人员在应用生命周期中各自的关注点，明晰责任与界限，聚焦自身业务，同时又依然能紧密协作。

### 一 什么是DevOps？为什么基于Kubernetes构建？

简单来说，研发工程师需要和运维工程师深度的合作，同时通过一系列工具保证研发更加顺畅，从而更容易的接触生产环境。到2013年，Docker出现了，工程师可以第一次到软件生产环境中定义，通过Docker image完成单机软件的交付和分发。此时DevOps开始慢慢落地。2015年开始，DevOps相关的工具越来越多，资源利用率出现了一些问题，CNCF的成立使得DevOps的实践往Kubernetes上走。

为什么阿里基于Kubernetes构建DevOps平台？

1）阿里基于Kubernetes的无限资源池与基础设施能力

- 大规模 – 单集群最高可达10000节点、百万Pod
- 高性能 – 秒级扩容，智能伸缩，神龙 + 安全容器
- 极致弹性 – 分钟级拆解公有云计算资源，无限资源池

2）社区围绕Kubernetes已经具备丰富的DevOps生态基础功能

- 源码到容器镜像仓库，Kubernetes是容器平台事实标准：Github/DockerHub
- CI/CD流水线、任务编排、发布策略：Argo/Teckton/Spinnaker/Jenkins-X/Flagger
- 镜像打包、分发：Helm/CNAB
- 丰富的应用运行负载支撑：Deployment(无状态)/StatefulSet(有状态)/OpenKruise(原生有状态增强)
- 丰富的弹性和应用扩缩容能力：HPA/KEDA

### 二 基于Kubernetes的DevOps平台新挑战

下图展示了一个云原生下的DevOps流水线的典型流程。

![image.png](https://ucc.alicdn.com/pic/developer-ecology/16ae9ed9b4584179b1165d703618a74d.png)



- 挑战一：**云资源与 DevOps 平台体验割裂**

  - DevOps流程中充斥着大量需要外部平台创建的过程：

  ![image.png](https://ucc.alicdn.com/pic/developer-ecology/c17f07d41a614b658bf613533b367fc1.png)

  

- 挑战二：**研发、运维、基础设施关注点耦合**

  - 下图是常用的K8s的YAML配置文件，大家经常吐槽这个配置文件很复杂。简单来说YAML配置文件可以分为三大块，一块是运维比较关心的配置，包括实例数，策略和发布。第二块是研发关心的，涉及到镜像、端口号等。第三块是基础设施工程师看得懂的，如调度策略等。K8s的配置文件中将方方面面的信息都耦合在一起，这对K8s工程师来说是非常适合的，但是对应用侧的终端工程师而言，有很多不需要关心的配置指标。

  ![image.png](https://ucc.alicdn.com/pic/developer-ecology/90a0a82ea12e4f68b33d6069907475f2.png)

- 挑战三：**平台的自定义封装，简单却能力不足**

  - DevOps平台对K8s能力封装抽象，只剩下5个Deployment的字段需要研发填写。从用户角度而言，这种设置非常好用简单。但是针对稍微复杂的应用，涉及到应用状态管理，健康检查等等一系列的操作，此时这5个字段是不够的。

  ![image.png](https://ucc.alicdn.com/pic/developer-ecology/1ac00a3b1ee143e68056154dbadeae8c.png)

- 挑战四：CRD 扩展能力强大，DevOps 平台无法直接复用

  - CRD(Customize Resource Definition)扩展能力强大，几乎所有软件都可以通过CRD的方式进行扩展，包括数据库、存储、安全、编排、依赖管理、发布等。但是**对DevOps平台来说，上面接口并没有向用户暴露，导致无法直接复用。**

  ![image.png](https://ucc.alicdn.com/pic/developer-ecology/24c5fe56aa384097a6af140d0ee182fb.png)

- 挑战五：DevOps 平台开发的新能力使用**门槛高**

  - 如果平台想要扩展一些能力，而原生的自动扩缩容能力不太合适，希望开发定时的扩缩容YAML文件，随着业务情况而设置。但此时用户使用YAML的门槛非常高，不清楚如何使用YAML。随着新能力开发越来越多，能力之间会出现冲突，这也非常难以管理。

  ![image.png](https://ucc.alicdn.com/pic/developer-ecology/fcad9167b21549a2b4aabf87246db843.png)

- 挑战六：不同 DevOps 平台需要完全重新对接
  - 难与生态进行对接。**如RDS，SLB的能力**都嵌到YAML文件中，**无法复用**，几乎不具备原子化能力。同时无法协作，无法提供给兄弟部门或生态使用，只能给内部封闭生态使用。上层系统不同应用对接DevOps平台时，需要写不同格式的YAML，这也是非常痛苦的。

### 三 OAM应用模型的技术原理

- Component组件

  - OAM中常见的概念是Component组件，完全从研发角度定义的待部署单元
  - OAM中会定义标准的架构ContaineriseWorkload，表示工作负载部分，里面是待部署单元的具体描述。这时就**可以解决关注点分离的问题**，帮助应用侧工程师去掉很多细节，只需要关心开发需要关注的端口号，镜像等等。

  ![image.png](https://ucc.alicdn.com/pic/developer-ecology/b06a24d9cdb240499ba152a17901cb88.png)

  - **应对挑战一**，在OAM中可以定义数据库表达资源需要使用云资源，Workload中可以根据自己的需要定义不同的组件，包括基于虚拟机的应用、或者老的Function应用。组件是应用开发者关心的。

  ![image.png](https://ucc.alicdn.com/pic/developer-ecology/7060b3612e764aa79833482d90cfafca.png)

- Trait

  - 如果只是组件，组合起来就可以构建简单的应用。如果关心应用运维的问题，OAM中有Trait的概念，指的是在原来组件的基础上附加一些特征。特征指的是运维的能力，如手动扩缩容能力、外部访问能力、发布、负载均衡。弹性扩缩容、基于流量的管理等等。**通过OAM的Trait可以很灵活的得到插件化扩充能力。不同的component绑定不同的特征。**

  ![image.png](https://ucc.alicdn.com/pic/developer-ecology/2c2190ce2fc94ce49dc828ba94e9b378.png)

- Scope

  - Component，Trait以及所有组装起来的Application Configuration就是OAM中的三种主要的概念。但当多个组件共同协作时应该如何处理？OAM中有个边界Scope的概念，是一种特殊的Trait，将多个Component组合在一起，共享一组资源组，CPU等特征用Scope表示，拓展多个组件的共同特征。

  ![image.png](https://ucc.alicdn.com/pic/developer-ecology/a710894b31d94144ae920daeaac99eb9.png)



### 四 OAM加持下的下一代DevOps技术

- OAM：以应用为中心的分层模型
  - OAM是以应用为中心的分层模型，首先需要运行在服务端的OAM解释器，对于YAML的读取需要通过OAM解释器。OAM提供Trait，Component让用户填写，编成APP Config。APP Config通过OAM解释器具备Deployment，Ingress，HPA或者云资源等能力。**这种方法可以将研发、运维基于基础设施进行分层，研发关心Component，运维关心Trait，基础设施通过OAM解释器提供各种能力**，与K8s紧密结合，对其应用概念做了补充。

![image.png](https://ucc.alicdn.com/pic/developer-ecology/db03bc8b7bb64fd3854530e39ecaaed2.png)

- 分层
- 模块化
- 可复用

- 快速的纳入K8s生态已有Operater能力
  - OAM可以快速的纳入K8s生态已有的Operater能力，下图左边的Component中是一个CRD的实例，右边是Trait中的CRD的实例，中间表示Component底下的Workload和Trait分别对应了K8s自定义资源的能力。如果想要使用K8s中的某些能力，只需要在Trait中写入相应的字段即可。

![image.png](https://ucc.alicdn.com/pic/developer-ecology/388ee760435445188ad1af1b93d1255a.png)

- OAM框架解决组件依赖关系和启动顺序
  - OAM框架解决组件依赖关系和启动顺序。OAM Runtime，OAM解释器会将组件依赖关系和启动顺序处理好，下图中Component之间有dependency关系，Trait与Component之间有preComponent或者postComponent等关系。

![image.png](https://ucc.alicdn.com/pic/developer-ecology/23cbbde0589c4b35b4a9f4cbc0d67238.png)

- OAM Trait灵活解决资源绑定难题
  - 启动顺序厘清之后涉及到资源绑定问题，一边是使用的数据库，另一边是Web的程序，Web的程序绑定数据库连接串资源。在OAM中只需要写一个Trait就可以解决资源绑定问题，下图右边，K8s通过Secret承载连接串信息，Service Binding Trait对应一个运行的Operator，Web Hook拿到Secret后注入进数据库中。

![image.png](https://ucc.alicdn.com/pic/developer-ecology/5847a820fb354bd6b5e3428d98ef500b.png)

- Workload与Trait交互机制
  - 大家会考虑接入OAM会不会比较麻烦，需不需要改代码。OAM设计了Workload与Trait交互机制，OAM内部零改造，只需要扩展Workload和Trait。**首先，Component中创建Workload实例，再创建Trait实例**，只需要在Trait中查看Workload的Definition，从而配置Trait中需要的能力。

![image.png](https://ucc.alicdn.com/pic/developer-ecology/b18bedcd8c8142f099f14e3f86e2e2c4.png)

如果开发了新的能力，碰到冲突问题也是非常头痛的。在OAM框架中定义Trait时，可以检查哪些字段是冲突的，拒绝掉新的应用的创建，从而保障Trait之间的兼容性，使得运维问题可发现、可管理。

![image.png](https://ucc.alicdn.com/pic/developer-ecology/38981f7f382541b5a7bc19dacca67d51.png)

- OAM：无限能力的DevOps平台体系
  - 下图是DevOps平台体系，最下层是OAM Runtime，一部分是Workload，对应运行时的承载的Runtime，如Function、Container、虚拟机、Serverless Service等。另一部分是Trait，对应运维能力，如发布、弹性扩缩容、日志、安全等等。再上一层可以根据场景化组合（Application Profile）组装成不同的业务形态平台，不同平台可以使用不同组合的Workload和Trait，具备不同的能力。**通过OAM标准化的模型构建无限能力的DevOps平台，满足各种场景的需要。**

![image.png](https://ucc.alicdn.com/pic/developer-ecology/d2ed7043498e4499a1cd08e33cda2497.png)

在用户侧，OAM加持下的研发DevOps流程在镜像构建完成之后使用达到统一，OAM提供了APP Config，包含不同的Component，每个Component包含不同的运维能力Trait，支持不同的环境，如测试环境、生成环境。OAM配置统一，适合不同的云，可以拿到不同的集群中直接运行。在K8s侧，用户只需要装上插件，就可以很方便的嵌入很多丰富的能力。

![image.png](https://ucc.alicdn.com/pic/developer-ecology/718ef8859c7e4a4498378a2b60f860cc.png)

运维 Kubernetes 负载均衡 安全 Cloud Native Devops 数据库 云计算 Docker 容器











